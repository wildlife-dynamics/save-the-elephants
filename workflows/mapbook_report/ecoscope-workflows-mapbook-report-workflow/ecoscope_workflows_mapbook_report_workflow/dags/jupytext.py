# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Mapbook Report
# TODO: top level description

# %% [markdown]
# ## Imports

import os

from ecoscope_workflows_core.tasks.analysis import (
    dataframe_column_nunique,
    dataframe_column_sum,
)
from ecoscope_workflows_core.tasks.config import set_workflow_details
from ecoscope_workflows_core.tasks.filter import set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers, split_groups
from ecoscope_workflows_core.tasks.io import (
    persist_text,
    set_er_connection,
    set_gee_connection,
)
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view,
    create_single_value_widget_single_view,
    create_text_widget_single_view,
    gather_dashboard,
    merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped,
    any_is_empty_df,
    never,
)
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index,
    map_columns,
    map_values_with_unit,
    sort_values,
)
from ecoscope_workflows_ext_custom.tasks.io import html_to_png, load_df
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    calculate_elliptical_time_density,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    determine_season_windows,
    get_subjectgroup_observations,
    persist_df,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    process_relocations,
    relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polygon_layer,
    create_polyline_layer,
    draw_ecomap,
    set_base_maps,
)
from ecoscope_workflows_ext_ecoscope.tasks.skip import all_geometry_are_none
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_classification,
    apply_color_map,
    classify_is_night,
)
from ecoscope_workflows_ext_ste.tasks import (
    annotate_gdf_dict_with_geometry_type,
    build_mapbook_report_template,
    calculate_seasonal_home_range,
    combine_map_layers,
    create_context_page,
    create_map_layers_from_annotated_dict,
    create_mapbook_context,
    create_report_context_from_tuple,
    create_seasonal_labels,
    create_view_state_from_gdf,
    dataframe_column_first_unique_str,
    fetch_and_persist_file,
    filter_by_value,
    find_landdx_gpkg_path,
    flatten_tuple,
    generate_ecograph_raster,
    generate_mcp_gdf,
    get_duration,
    get_split_group_column,
    get_split_group_names,
    label_quarter_status,
    make_text_layer,
    merge_docx_files,
    modify_quarter_status_colors,
    retrieve_feature_gdf,
    round_off_values,
    split_gdf_by_column,
    zip_grouped_by_key,
    zip_lists,
)

# %% [markdown]
# ## Initialize workflow metadata

# %%
# parameters

initialize_workflow_metadata_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


initialize_workflow_metadata = (
    set_workflow_details.set_task_instance_id("initialize_workflow_metadata")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**initialize_workflow_metadata_params)
    .call()
)


# %% [markdown]
# ## Define time range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
)

# %%
# call the task


time_range = (
    set_time_range.set_task_instance_id("time_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        time_format="%d %b %Y %H:%M:%S %Z",
        timezone={
            "label": "UTC",
            "tzCode": "UTC",
            "name": "UTC",
            "utc_offset": "+00:00",
        },
        **time_range_params,
    )
    .call()
)


# %% [markdown]
# ## Configure grouping strategy

# %%
# parameters

groupers_params = dict(
    groupers=...,
)

# %%
# call the task


groupers = (
    set_groupers.set_task_instance_id("groupers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**groupers_params)
    .call()
)


# %% [markdown]
# ## Configure base map layers

# %%
# parameters

configure_base_maps_params = dict(
    base_maps=...,
)

# %%
# call the task


configure_base_maps = (
    set_base_maps.set_task_instance_id("configure_base_maps")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**configure_base_maps_params)
    .call()
)


# %% [markdown]
# ## Download mapbook cover page templates

# %%
# parameters

download_mapbook_cover_page_params = dict()

# %%
# call the task


download_mapbook_cover_page = (
    fetch_and_persist_file.set_task_instance_id("download_mapbook_cover_page")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        url="https://www.dropbox.com/scl/fi/1373gi65ji918rxele5h9/cover_page_v3.docx?rlkey=ur01wtpa98tcyq8f0f6dtksl8&st=eq39sgwz&dl=0",
        output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        overwrite_existing=False,
        unzip=False,
        retries=3,
        **download_mapbook_cover_page_params,
    )
    .call()
)


# %% [markdown]
# ## Download mapbook section templates

# %%
# parameters

download_sect_templates_params = dict()

# %%
# call the task


download_sect_templates = (
    fetch_and_persist_file.set_task_instance_id("download_sect_templates")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        url="https://www.dropbox.com/scl/fi/0as1u7uuhia7emp5cqxfl/mapbook_subject_template_v6.docx?rlkey=4nzn4qa2hu0v3fqo8bpki4tgu&st=kco28x6g&dl=0",
        output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        overwrite_existing=False,
        unzip=False,
        retries=3,
        **download_sect_templates_params,
    )
    .call()
)


# %% [markdown]
# ## Download logo path

# %%
# parameters

download_logo_path_params = dict()

# %%
# call the task


download_logo_path = (
    fetch_and_persist_file.set_task_instance_id("download_logo_path")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        url="https://www.dropbox.com/scl/fi/1gn84pq9c7tedgg3k90qt/save-the-elephants.jpg?rlkey=ump7g2hcc2pn0pd5nst203c7w&st=jlwbhik9&dl=0",
        output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        overwrite_existing=False,
        unzip=False,
        retries=3,
        **download_logo_path_params,
    )
    .call()
)


# %% [markdown]
# ## Download landDx db and extract

# %%
# parameters

download_ldx_db_params = dict()

# %%
# call the task


download_ldx_db = (
    fetch_and_persist_file.set_task_instance_id("download_ldx_db")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        url="https://maraelephant.maps.arcgis.com/sharing/rest/content/items/6da0c9bdd43d4dd0ac59a4f3cd73dcab/data",
        overwrite_existing=False,
        unzip=True,
        retries=3,
        **download_ldx_db_params,
    )
    .call()
)


# %% [markdown]
# ## Find landDx gpkg path

# %%
# parameters

return_ldx_path_params = dict()

# %%
# call the task


return_ldx_path = (
    find_landdx_gpkg_path.set_task_instance_id("return_ldx_path")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(output_dir=download_ldx_db, **return_ldx_path_params)
    .call()
)


# %% [markdown]
# ## Load landDx gpkg

# %%
# parameters

load_landdx_params = dict()

# %%
# call the task


load_landdx = (
    load_df.set_task_instance_id("load_landdx")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        file_path=return_ldx_path,
        layer="landDx_polygons",
        deserialize_json=False,
        **load_landdx_params,
    )
    .call()
)


# %% [markdown]
# ## Filter loaded landDX by AOI

# %%
# parameters

filter_landdx_aoi_params = dict()

# %%
# call the task


filter_landdx_aoi = (
    filter_by_value.set_task_instance_id("filter_landdx_aoi")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=load_landdx,
        column_name="type",
        value=["Community Conservancy", "National Reserve", "National Park"],
        **filter_landdx_aoi_params,
    )
    .call()
)


# %% [markdown]
# ## Create text layer from filtered aoi

# %%
# parameters

custom_text_layer_params = dict()

# %%
# call the task


custom_text_layer = (
    make_text_layer.set_task_instance_id("custom_text_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        txt_gdf=filter_landdx_aoi,
        label_column="label",
        name_column="name",
        use_centroid=True,
        color=[0, 0, 0, 255],
        size=16,
        font_weight="normal",
        font_family="Arial",
        text_anchor="middle",
        alignment_baseline="center",
        pickable=True,
        tooltip_columns=None,
        zoom=False,
        target_crs="epsg:4326",
        **custom_text_layer_params,
    )
    .call()
)


# %% [markdown]
# ## Split landDx layers by type

# %%
# parameters

split_landdx_by_type_params = dict()

# %%
# call the task


split_landdx_by_type = (
    split_gdf_by_column.set_task_instance_id("split_landdx_by_type")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(gdf=filter_landdx_aoi, column="type", **split_landdx_by_type_params)
    .call()
)


# %% [markdown]
# ## Annotate geometry types to landdx dicts

# %%
# parameters

annotate_geometry_types_params = dict()

# %%
# call the task


annotate_geometry_types = (
    annotate_gdf_dict_with_geometry_type.set_task_instance_id("annotate_geometry_types")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(gdf_dict=split_landdx_by_type, **annotate_geometry_types_params)
    .call()
)


# %% [markdown]
# ## Style landDx map layers

# %%
# parameters

create_styled_landdx_layers_params = dict()

# %%
# call the task


create_styled_landdx_layers = (
    create_map_layers_from_annotated_dict.set_task_instance_id(
        "create_styled_landdx_layers"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        annotated_dict=annotate_geometry_types,
        style_config={
            "styles": {
                "Community Conservancy": {
                    "get_fill_color": [85, 107, 47],
                    "get_line_color": [85, 107, 47],
                    "opacity": 0.15,
                    "stroked": True,
                    "get_line_width": 1.55,
                },
                "National Reserve": {
                    "get_fill_color": [143, 188, 139],
                    "get_line_color": [143, 188, 139],
                    "opacity": 0.15,
                    "stroked": True,
                    "get_line_width": 1.55,
                },
                "National Park": {
                    "get_fill_color": [255, 250, 205],
                    "get_line_color": [255, 250, 205],
                    "opacity": 0.15,
                    "stroked": True,
                    "get_line_width": 1.55,
                },
            },
            "legend": {
                "labels": [
                    "Community Conservancy",
                    "National Reserve",
                    "National Park",
                ],
                "colors": ["#556b2f", "#8fbc8b", "#fffacd"],
            },
        },
        **create_styled_landdx_layers_params,
    )
    .call()
)


# %% [markdown]
# ## Connect to ER instance

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.set_task_instance_id("er_client_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Connect to EE

# %%
# parameters

gee_project_name_params = dict(
    data_source=...,
)

# %%
# call the task


gee_project_name = (
    set_gee_connection.set_task_instance_id("gee_project_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**gee_project_name_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

subject_observations_params = dict(
    subject_group_name=...,
)

# %%
# call the task


subject_observations = (
    get_subjectgroup_observations.set_task_instance_id("subject_observations")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        raise_on_empty=False,
        include_details=False,
        include_subjectsource_details=False,
        **subject_observations_params,
    )
    .call()
)


# %% [markdown]
# ## Transform observations to relocations

# %%
# parameters

subject_reloc_params = dict()

# %%
# call the task


subject_reloc = (
    process_relocations.set_task_instance_id("subject_reloc")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        observations=subject_observations,
        relocs_columns=[
            "groupby_col",
            "fixtime",
            "junk_status",
            "geometry",
            "extra__subject__name",
            "extra__subject__hex",
            "extra__subject__sex",
            "extra__created_at",
            "extra__subject__subject_subtype",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **subject_reloc_params,
    )
    .call()
)


# %% [markdown]
# ## Annotate relocations with Day/Night Labels

# %%
# parameters

annotate_day_night_params = dict()

# %%
# call the task


annotate_day_night = (
    classify_is_night.set_task_instance_id("annotate_day_night")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(relocations=subject_reloc, **annotate_day_night_params)
    .call()
)


# %% [markdown]
# ## Convert relocations to trajectories

# %%
# parameters

convert_to_trajectories_params = dict(
    trajectory_segment_filter=...,
)

# %%
# call the task


convert_to_trajectories = (
    relocations_to_trajectory.set_task_instance_id("convert_to_trajectories")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(relocations=annotate_day_night, **convert_to_trajectories_params)
    .call()
)


# %% [markdown]
# ## Add temporal index to trajectories

# %%
# parameters

add_temporal_index_to_traj_params = dict()

# %%
# call the task


add_temporal_index_to_traj = (
    add_temporal_index.set_task_instance_id("add_temporal_index_to_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_to_trajectories,
        time_col="segment_start",
        groupers=groupers,
        cast_to_datetime=True,
        format="mixed",
        **add_temporal_index_to_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Classify trajectories by speed

# %%
# parameters

classify_trajectory_speed_bins_params = dict()

# %%
# call the task


classify_trajectory_speed_bins = (
    apply_classification.set_task_instance_id("classify_trajectory_speed_bins")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=add_temporal_index_to_traj,
        input_column_name="speed_kmhr",
        output_column_name="speed_bins",
        classification_options={"scheme": "equal_interval", "k": 6},
        label_options={"label_ranges": False, "label_decimals": 1},
        **classify_trajectory_speed_bins_params,
    )
    .call()
)


# %% [markdown]
# ## Label trajectories by quarter

# %%
# parameters

label_trajectory_quarters_params = dict()

# %%
# call the task


label_trajectory_quarters = (
    label_quarter_status.set_task_instance_id("label_trajectory_quarters")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        gdf=classify_trajectory_speed_bins,
        timestamp_col="segment_start",
        **label_trajectory_quarters_params,
    )
    .call()
)


# %% [markdown]
# ## Rename trajectory columnns

# %%
# parameters

rename_traj_cols_params = dict()

# %%
# call the task


rename_traj_cols = (
    map_columns.set_task_instance_id("rename_traj_cols")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "extra__hex": "hex_color",
            "extra__is_night": "is_night",
            "extra__name": "subject_name",
            "extra__sex": "subject_sex",
            "extra__subject_subtype": "subject_subtype",
            "extra__created_at": "created_at",
        },
        df=label_trajectory_quarters,
        **rename_traj_cols_params,
    )
    .call()
)


# %% [markdown]
# ## Persist trajectories as gpkg

# %%
# parameters

persist_trajectory_df_params = dict()

# %%
# call the task


persist_trajectory_df = (
    persist_df.set_task_instance_id("persist_trajectory_df")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=rename_traj_cols,
        filetype="gpkg",
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename="trajectories",
        **persist_trajectory_df_params,
    )
    .call()
)


# %% [markdown]
# ## Persist relocations as gpkg

# %%
# parameters

persist_relocs_df_params = dict()

# %%
# call the task


persist_relocs_df = (
    persist_df.set_task_instance_id("persist_relocs_df")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=annotate_day_night,
        filetype="gpkg",
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename="relocations",
        **persist_relocs_df_params,
    )
    .call()
)


# %% [markdown]
# ## Split trajectories by group

# %%
# parameters

split_trajectories_by_group_params = dict()

# %%
# call the task


split_trajectories_by_group = (
    split_groups.set_task_instance_id("split_trajectories_by_group")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=rename_traj_cols, groupers=groupers, **split_trajectories_by_group_params
    )
    .call()
)


# %% [markdown]
# ## Get subject group names

# %%
# parameters

split_group_column_params = dict()

# %%
# call the task


split_group_column = (
    get_split_group_column.set_task_instance_id("split_group_column")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(split_data=split_trajectories_by_group, **split_group_column_params)
    .call()
)


# %% [markdown]
# ## Assign quarter status colors

# %%
# parameters

assign_quarter_colors_traj_params = dict()

# %%
# call the task


assign_quarter_colors_traj = (
    modify_quarter_status_colors.set_task_instance_id("assign_quarter_colors_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(grouper_value=split_group_column, **assign_quarter_colors_traj_params)
    .mapvalues(argnames=["gdf"], argvalues=split_trajectories_by_group)
)


# %% [markdown]
# ## Sort trajectories by speed bins

# %%
# parameters

sort_trajectories_by_speed_params = dict()

# %%
# call the task


sort_trajectories_by_speed = (
    sort_values.set_task_instance_id("sort_trajectories_by_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="speed_bins",
        na_position="last",
        ascending=True,
        **sort_trajectories_by_speed_params,
    )
    .mapvalues(argnames=["df"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Apply colormap to speed bins

# %%
# parameters

apply_speed_colormap_params = dict()

# %%
# call the task


apply_speed_colormap = (
    apply_color_map.set_task_instance_id("apply_speed_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="speed_bins",
        output_column_name="speed_bins_colormap",
        colormap=["#1a9850", "#91cf60", "#d9ef8b", "#fee08b", "#fc8d59", "#d73027"],
        **apply_speed_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_trajectories_by_speed)
)


# %% [markdown]
# ## Format speed bins for legend

# %%
# parameters

format_speed_bin_labels_params = dict()

# %%
# call the task


format_speed_bin_labels = (
    map_values_with_unit.set_task_instance_id("format_speed_bin_labels")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="speed_bins",
        output_column_name="speed_bins_formatted",
        original_unit="km/h",
        new_unit="km/h",
        decimal_places=1,
        **format_speed_bin_labels_params,
    )
    .mapvalues(argnames=["df"], argvalues=apply_speed_colormap)
)


# %% [markdown]
# ## Format speed values for display

# %%
# parameters

format_speed_values_params = dict()

# %%
# call the task


format_speed_values = (
    map_values_with_unit.set_task_instance_id("format_speed_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="speed_kmhr",
        output_column_name="speed_kmhr",
        original_unit="km/h",
        new_unit="km/h",
        decimal_places=1,
        **format_speed_values_params,
    )
    .mapvalues(argnames=["df"], argvalues=format_speed_bin_labels)
)


# %% [markdown]
# ## Generate speedmap layers

# %%
# parameters

generate_speedmap_layers_params = dict(
    zoom=...,
)

# %%
# call the task


generate_speedmap_layers = (
    create_polyline_layer.set_task_instance_id("generate_speedmap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"color_column": "speed_bins_colormap"},
        legend={
            "label_column": "speed_bins_formatted",
            "color_column": "speed_bins_colormap",
        },
        tooltip_columns=[
            "is_night",
            "subject_name",
            "segment_start",
            "dist_meters",
            "timespan_seconds",
            "subject_sex",
        ],
        **generate_speedmap_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=format_speed_values)
)


# %% [markdown]
# ## Zoom speed trajs by view state

# %%
# parameters

zoom_speed_traj_view_params = dict()

# %%
# call the task


zoom_speed_traj_view = (
    create_view_state_from_gdf.set_task_instance_id("zoom_speed_traj_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, **zoom_speed_traj_view_params)
    .mapvalues(argnames=["gdf"], argvalues=format_speed_values)
)


# %% [markdown]
# ## Combine landDx and speedmap layers

# %%
# parameters

ldx_speed_layers_params = dict()

# %%
# call the task


ldx_speed_layers = (
    combine_map_layers.set_task_instance_id("ldx_speed_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        static_layers=[create_styled_landdx_layers, custom_text_layer],
        **ldx_speed_layers_params,
    )
    .mapvalues(argnames=["grouped_layers"], argvalues=generate_speedmap_layers)
)


# %% [markdown]
# ## Zip speedmap layers and zoom values

# %%
# parameters

zip_speed_zoom_values_params = dict()

# %%
# call the task


zip_speed_zoom_values = (
    zip_grouped_by_key.set_task_instance_id("zip_speed_zoom_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=ldx_speed_layers,
        right=zoom_speed_traj_view,
        **zip_speed_zoom_values_params,
    )
    .call()
)


# %% [markdown]
# ## Draw Speepmap by group

# %%
# parameters

draw_speed_ecomap_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_speed_ecomap = (
    draw_ecomap.set_task_instance_id("draw_speed_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "Speed Values(Km/h)"},
        static=False,
        title=None,
        max_zoom=12,
        **draw_speed_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=zip_speed_zoom_values)
)


# %% [markdown]
# ## Persist speedmap HTML paths

# %%
# parameters

persist_speed_ecomap_urls_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


persist_speed_ecomap_urls = (
    persist_text.set_task_instance_id("persist_speed_ecomap_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **persist_speed_ecomap_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=draw_speed_ecomap)
)


# %% [markdown]
# ## Create speedmap widgets

# %%
# parameters

create_speedmap_widgets_params = dict()

# %%
# call the task


create_speedmap_widgets = (
    create_map_widget_single_view.set_task_instance_id("create_speedmap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Speedmap", **create_speedmap_widgets_params)
    .map(argnames=["view", "data"], argvalues=persist_speed_ecomap_urls)
)


# %% [markdown]
# ## Merge speedmap widgets

# %%
# parameters

merge_speedmap_widgets_params = dict()

# %%
# call the task


merge_speedmap_widgets = (
    merge_widget_views.set_task_instance_id("merge_speedmap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=create_speedmap_widgets, **merge_speedmap_widgets_params)
    .call()
)


# %% [markdown]
# ## Sort trajectories by Night/Day

# %%
# parameters

sort_trajs_by_day_night_params = dict()

# %%
# call the task


sort_trajs_by_day_night = (
    sort_values.set_task_instance_id("sort_trajs_by_day_night")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="is_night",
        ascending=False,
        na_position="last",
        **sort_trajs_by_day_night_params,
    )
    .mapvalues(argnames=["df"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Apply color to trajectories by Day/Night

# %%
# parameters

apply_day_night_colormap_params = dict()

# %%
# call the task


apply_day_night_colormap = (
    apply_color_map.set_task_instance_id("apply_day_night_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        colormap=["#292965", "#e7a553"],
        input_column_name="is_night",
        output_column_name="day_night_colors",
        **apply_day_night_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_trajs_by_day_night)
)


# %% [markdown]
# ## Create Day/Night ecomap layers

# %%
# parameters

generate_day_night_ecomap_layers_params = dict(
    zoom=...,
)

# %%
# call the task


generate_day_night_ecomap_layers = (
    create_polyline_layer.set_task_instance_id("generate_day_night_ecomap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"color_column": "day_night_colors"},
        legend={"labels": ["Night", "Day"], "colors": ["#292965", "#e7a553"]},
        tooltip_columns=["is_night", "subject_name", "subject_sex"],
        **generate_day_night_ecomap_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=apply_day_night_colormap)
)


# %% [markdown]
# ## Zoom day/night trajs by view state

# %%
# parameters

zoom_dn_view_params = dict()

# %%
# call the task


zoom_dn_view = (
    create_view_state_from_gdf.set_task_instance_id("zoom_dn_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, **zoom_dn_view_params)
    .mapvalues(argnames=["gdf"], argvalues=apply_day_night_colormap)
)


# %% [markdown]
# ## Combine landDx and Day/Night ecomap layers

# %%
# parameters

ldx_dn_layers_params = dict()

# %%
# call the task


ldx_dn_layers = (
    combine_map_layers.set_task_instance_id("ldx_dn_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        static_layers=[create_styled_landdx_layers, custom_text_layer],
        **ldx_dn_layers_params,
    )
    .mapvalues(argnames=["grouped_layers"], argvalues=generate_day_night_ecomap_layers)
)


# %% [markdown]
# ## Zip day/night layers and zoom values

# %%
# parameters

dn_view_zip_params = dict()

# %%
# call the task


dn_view_zip = (
    zip_grouped_by_key.set_task_instance_id("dn_view_zip")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(left=ldx_dn_layers, right=zoom_dn_view, **dn_view_zip_params)
    .call()
)


# %% [markdown]
# ## Draw Day/Night ecomaps by group

# %%
# parameters

draw_day_night_ecomap_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_day_night_ecomap = (
    draw_ecomap.set_task_instance_id("draw_day_night_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "Night Day Tracks"},
        static=False,
        title=None,
        max_zoom=12,
        **draw_day_night_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=dn_view_zip)
)


# %% [markdown]
# ## Persist Day/Night ecomap HTML paths

# %%
# parameters

persist_day_night_ecomap_urls_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


persist_day_night_ecomap_urls = (
    persist_text.set_task_instance_id("persist_day_night_ecomap_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **persist_day_night_ecomap_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=draw_day_night_ecomap)
)


# %% [markdown]
# ## Create Day/Night ecomap widgets

# %%
# parameters

create_day_night_ecomap_widgets_params = dict()

# %%
# call the task


create_day_night_ecomap_widgets = (
    create_map_widget_single_view.set_task_instance_id(
        "create_day_night_ecomap_widgets"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Night Day Tracks", **create_day_night_ecomap_widgets_params)
    .map(argnames=["view", "data"], argvalues=persist_day_night_ecomap_urls)
)


# %% [markdown]
# ## Merge Day/Night ecomap widgets

# %%
# parameters

merge_day_night_ecomap_widgets_params = dict()

# %%
# call the task


merge_day_night_ecomap_widgets = (
    merge_widget_views.set_task_instance_id("merge_day_night_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=create_day_night_ecomap_widgets, **merge_day_night_ecomap_widgets_params
    )
    .call()
)


# %% [markdown]
# ## Sort trajectories by quarter status

# %%
# parameters

sort_trajs_by_quarter_status_params = dict()

# %%
# call the task


sort_trajs_by_quarter_status = (
    sort_values.set_task_instance_id("sort_trajs_by_quarter_status")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="quarter_status",
        ascending=False,
        na_position="last",
        **sort_trajs_by_quarter_status_params,
    )
    .mapvalues(argnames=["df"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Create quarter status ecomap layers

# %%
# parameters

generate_quarter_ecomap_layers_params = dict(
    zoom=...,
)

# %%
# call the task


generate_quarter_ecomap_layers = (
    create_polyline_layer.set_task_instance_id("generate_quarter_ecomap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"color_column": "quarter_status_colors"},
        legend={
            "label_column": "quarter_status",
            "color_column": "quarter_status_colors",
        },
        tooltip_columns=["is_night", "subject_name", "subject_sex", "quarter_status"],
        **generate_quarter_ecomap_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=sort_trajs_by_quarter_status)
)


# %% [markdown]
# ## Zoom quarter movement trajectories by view state

# %%
# parameters

zoom_qm_view_params = dict()

# %%
# call the task


zoom_qm_view = (
    create_view_state_from_gdf.set_task_instance_id("zoom_qm_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, **zoom_qm_view_params)
    .mapvalues(argnames=["gdf"], argvalues=format_speed_values)
)


# %% [markdown]
# ## Combine landDx and quarter status ecomap layers

# %%
# parameters

combine_quarter_ecomap_layers_params = dict()

# %%
# call the task


combine_quarter_ecomap_layers = (
    combine_map_layers.set_task_instance_id("combine_quarter_ecomap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        static_layers=[create_styled_landdx_layers, custom_text_layer],
        **combine_quarter_ecomap_layers_params,
    )
    .mapvalues(argnames=["grouped_layers"], argvalues=generate_quarter_ecomap_layers)
)


# %% [markdown]
# ## Zip quarter movement layers and zoom values

# %%
# parameters

qm_view_zip_params = dict()

# %%
# call the task


qm_view_zip = (
    zip_grouped_by_key.set_task_instance_id("qm_view_zip")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=combine_quarter_ecomap_layers, right=zoom_qm_view, **qm_view_zip_params
    )
    .call()
)


# %% [markdown]
# ## Draw quarter status ecomaps by group

# %%
# parameters

draw_quarter_status_ecomap_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_quarter_status_ecomap = (
    draw_ecomap.set_task_instance_id("draw_quarter_status_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "Legend"},
        static=False,
        title=None,
        max_zoom=12,
        **draw_quarter_status_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=qm_view_zip)
)


# %% [markdown]
# ## Persist quarter status ecomap HTML paths

# %%
# parameters

persist_quarter_ecomap_urls_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


persist_quarter_ecomap_urls = (
    persist_text.set_task_instance_id("persist_quarter_ecomap_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **persist_quarter_ecomap_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=draw_quarter_status_ecomap)
)


# %% [markdown]
# ## Create quarter status ecomap widgets

# %%
# parameters

create_quarter_ecomap_widgets_params = dict()

# %%
# call the task


create_quarter_ecomap_widgets = (
    create_map_widget_single_view.set_task_instance_id("create_quarter_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Movement Overview", **create_quarter_ecomap_widgets_params)
    .map(argnames=["view", "data"], argvalues=persist_quarter_ecomap_urls)
)


# %% [markdown]
# ## Merge quarter status ecomap widgets

# %%
# parameters

merge_quarter_ecomap_widgets_params = dict()

# %%
# call the task


merge_quarter_ecomap_widgets = (
    merge_widget_views.set_task_instance_id("merge_quarter_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=create_quarter_ecomap_widgets, **merge_quarter_ecomap_widgets_params
    )
    .call()
)


# %% [markdown]
# ## Generate Home Range ecomap

# %%
# parameters

generate_etd_params = dict()

# %%
# call the task


generate_etd = (
    calculate_elliptical_time_density.set_task_instance_id("generate_etd")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        auto_scale_or_custom_cell_size={
            "auto_scale_or_custom": "Customize",
            "grid_cell_size": 2000,
        },
        crs="ESRI:53042",
        percentiles=[50.0, 60.0, 70.0, 80.0, 90.0, 95.0, 99.9],
        nodata_value="nan",
        band_count=1,
        max_speed_factor=1.05,
        expansion_factor=1.3,
        **generate_etd_params,
    )
    .mapvalues(argnames=["trajectory_gdf"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Determine seasonal windows

# %%
# parameters

determine_seasonal_windows_params = dict()

# %%
# call the task


determine_seasonal_windows = (
    determine_season_windows.set_task_instance_id("determine_seasonal_windows")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=gee_project_name,
        time_range=time_range,
        **determine_seasonal_windows_params,
    )
    .mapvalues(argnames=["roi"], argvalues=generate_etd)
)


# %% [markdown]
# ## Zip etd and grouped trajectories

# %%
# parameters

zip_etd_and_grouped_trajs_params = dict()

# %%
# call the task


zip_etd_and_grouped_trajs = (
    zip_grouped_by_key.set_task_instance_id("zip_etd_and_grouped_trajs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=determine_seasonal_windows,
        right=assign_quarter_colors_traj,
        **zip_etd_and_grouped_trajs_params,
    )
    .call()
)


# %% [markdown]
# ## Generate seasonal labels

# %%
# parameters

add_season_labels_params = dict()

# %%
# call the task


add_season_labels = (
    create_seasonal_labels.set_task_instance_id("add_season_labels")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**add_season_labels_params)
    .mapvalues(
        argnames=["seasons_df", "trajectories"], argvalues=zip_etd_and_grouped_trajs
    )
)


# %% [markdown]
# ## Generate MCP gdf

# %%
# parameters

calculate_mcp_params = dict()

# %%
# call the task


calculate_mcp = (
    generate_mcp_gdf.set_task_instance_id("calculate_mcp")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(planar_crs="ESRI:53042", **calculate_mcp_params)
    .mapvalues(argnames=["gdf"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Apply colormap to Home Range percentiles

# %%
# parameters

apply_etd_percentile_colormap_params = dict()

# %%
# call the task


apply_etd_percentile_colormap = (
    apply_color_map.set_task_instance_id("apply_etd_percentile_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="percentile",
        colormap="RdYlGn",
        output_column_name="percentile_colormap",
        **apply_etd_percentile_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=generate_etd)
)


# %% [markdown]
# ## Create Home Range ecomap layers

# %%
# parameters

generate_etd_ecomap_layers_params = dict(
    zoom=...,
)

# %%
# call the task


generate_etd_ecomap_layers = (
    create_polygon_layer.set_task_instance_id("generate_etd_ecomap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"fill_color_column": "percentile_colormap", "opacity": 0.55},
        legend={"label_column": "percentile", "color_column": "percentile_colormap"},
        tooltip_columns=["percentile"],
        **generate_etd_ecomap_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=apply_etd_percentile_colormap)
)


# %% [markdown]
# ## Create MCP polygon layer

# %%
# parameters

generate_mcp_layers_params = dict(
    zoom=...,
)

# %%
# call the task


generate_mcp_layers = (
    create_polygon_layer.set_task_instance_id("generate_mcp_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "get_fill_color": "#FFFFFF00",
            "get_line_color": "#ff1493",
            "get_line_width": 3.55,
            "opacity": 0.75,
            "stroked": True,
        },
        legend={"labels": ["MCP"], "colors": ["#ff1493"]},
        tooltip_columns=["area_km2"],
        **generate_mcp_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=calculate_mcp)
)


# %% [markdown]
# ## Zoom hr movement by view state

# %%
# parameters

zoom_hr_view_params = dict()

# %%
# call the task


zoom_hr_view = (
    create_view_state_from_gdf.set_task_instance_id("zoom_hr_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, **zoom_hr_view_params)
    .mapvalues(argnames=["gdf"], argvalues=apply_etd_percentile_colormap)
)


# %% [markdown]
# ## zip mcp and hr

# %%
# parameters

zip_mcp_hr_params = dict()

# %%
# call the task


zip_mcp_hr = (
    zip_grouped_by_key.set_task_instance_id("zip_mcp_hr")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=generate_mcp_layers, right=generate_etd_ecomap_layers, **zip_mcp_hr_params
    )
    .call()
)


# %% [markdown]
# ## Combine landDx and Home Range ecomap layers

# %%
# parameters

combine_landdx_hr_ecomap_layers_params = dict()

# %%
# call the task


combine_landdx_hr_ecomap_layers = (
    combine_map_layers.set_task_instance_id("combine_landdx_hr_ecomap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        static_layers=[create_styled_landdx_layers, custom_text_layer],
        **combine_landdx_hr_ecomap_layers_params,
    )
    .mapvalues(argnames=["grouped_layers"], argvalues=zip_mcp_hr)
)


# %% [markdown]
# ## Zip hr layers and zoom values

# %%
# parameters

hr_view_zip_params = dict()

# %%
# call the task


hr_view_zip = (
    zip_grouped_by_key.set_task_instance_id("hr_view_zip")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=combine_landdx_hr_ecomap_layers, right=zoom_hr_view, **hr_view_zip_params
    )
    .call()
)


# %% [markdown]
# ## Draw Home Range ecomap

# %%
# parameters

draw_hr_ecomap_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_hr_ecomap = (
    draw_ecomap.set_task_instance_id("draw_hr_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "ETD Metrics"},
        static=False,
        title=None,
        max_zoom=12,
        **draw_hr_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=hr_view_zip)
)


# %% [markdown]
# ## Persist Home Range ecomap HTML paths

# %%
# parameters

persist_hr_ecomap_urls_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


persist_hr_ecomap_urls = (
    persist_text.set_task_instance_id("persist_hr_ecomap_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **persist_hr_ecomap_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=draw_hr_ecomap)
)


# %% [markdown]
# ## Create Home Range ecomap widgets

# %%
# parameters

create_hr_ecomap_widgets_params = dict()

# %%
# call the task


create_hr_ecomap_widgets = (
    create_map_widget_single_view.set_task_instance_id("create_hr_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Home Range", **create_hr_ecomap_widgets_params)
    .map(argnames=["view", "data"], argvalues=persist_hr_ecomap_urls)
)


# %% [markdown]
# ## Merge Home Range ecomap widgets

# %%
# parameters

merge_hr_ecomap_widgets_params = dict()

# %%
# call the task


merge_hr_ecomap_widgets = (
    merge_widget_views.set_task_instance_id("merge_hr_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=create_hr_ecomap_widgets, **merge_hr_ecomap_widgets_params)
    .call()
)


# %% [markdown]
# ## Generate speed rasters

# %%
# parameters

generate_speed_raster_params = dict()

# %%
# call the task


generate_speed_raster = (
    generate_ecograph_raster.set_task_instance_id("generate_speed_raster")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        step_length=2000,
        dist_col="dist_meters",
        interpolation="mean",
        movement_covariate="speed",
        radius=2,
        cutoff=None,
        tortuosity_length=3,
        resolution=None,
        network_metric=None,
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename=None,
        **generate_speed_raster_params,
    )
    .mapvalues(argnames=["gdf"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Extract features from speed raster TIFFs

# %%
# parameters

extract_speed_rasters_params = dict()

# %%
# call the task


extract_speed_rasters = (
    retrieve_feature_gdf.set_task_instance_id("extract_speed_rasters")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**extract_speed_rasters_params)
    .mapvalues(argnames=["file_path"], argvalues=generate_speed_raster)
)


# %% [markdown]
# ## Sort speed features by value

# %%
# parameters

sort_speed_features_by_value_params = dict()

# %%
# call the task


sort_speed_features_by_value = (
    sort_values.set_task_instance_id("sort_speed_features_by_value")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="value",
        na_position="last",
        ascending=True,
        **sort_speed_features_by_value_params,
    )
    .mapvalues(argnames=["df"], argvalues=extract_speed_rasters)
)


# %% [markdown]
# ## Classify speed feature gdf

# %%
# parameters

classify_speed_features_params = dict()

# %%
# call the task


classify_speed_features = (
    apply_classification.set_task_instance_id("classify_speed_features")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="value",
        output_column_name="bins",
        classification_options={"scheme": "natural_breaks", "k": 6},
        label_options={"label_ranges": False, "label_decimals": 1},
        **classify_speed_features_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_speed_features_by_value)
)


# %% [markdown]
# ## Apply colormap to speed raster bins

# %%
# parameters

apply_speed_raster_colormap_params = dict()

# %%
# call the task


apply_speed_raster_colormap = (
    apply_color_map.set_task_instance_id("apply_speed_raster_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="bins",
        output_column_name="speedraster_bins_colors",
        colormap=["#1a9850", "#91cf60", "#d9ef8b", "#fee08b", "#fc8d59", "#d73027"],
        **apply_speed_raster_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=classify_speed_features)
)


# %% [markdown]
# ## Format speed raster bin labels

# %%
# parameters

format_speed_raster_labels_params = dict()

# %%
# call the task


format_speed_raster_labels = (
    map_values_with_unit.set_task_instance_id("format_speed_raster_labels")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="bins",
        output_column_name="bins_formatted",
        original_unit="km/h",
        new_unit="km/h",
        decimal_places=1,
        **format_speed_raster_labels_params,
    )
    .mapvalues(argnames=["df"], argvalues=apply_speed_raster_colormap)
)


# %% [markdown]
# ## Create speed raster map layers

# %%
# parameters

generate_raster_layers_params = dict(
    zoom=...,
)

# %%
# call the task


generate_raster_layers = (
    create_polygon_layer.set_task_instance_id("generate_raster_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"fill_color_column": "speedraster_bins_colors", "opacity": 0.55},
        legend={
            "label_column": "bins_formatted",
            "color_column": "speedraster_bins_colors",
        },
        tooltip_columns=["value", "bins", "speedraster_bins_colors"],
        **generate_raster_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=format_speed_raster_labels)
)


# %% [markdown]
# ## Zoom speed rasters by view state

# %%
# parameters

zoom_speedraster_view_params = dict()

# %%
# call the task


zoom_speedraster_view = (
    create_view_state_from_gdf.set_task_instance_id("zoom_speedraster_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, **zoom_speedraster_view_params)
    .mapvalues(argnames=["gdf"], argvalues=format_speed_raster_labels)
)


# %% [markdown]
# ## Combine landDx and speedraster map layers

# %%
# parameters

combine_seasonal_raster_layers_params = dict()

# %%
# call the task


combine_seasonal_raster_layers = (
    combine_map_layers.set_task_instance_id("combine_seasonal_raster_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        static_layers=[create_styled_landdx_layers, custom_text_layer],
        **combine_seasonal_raster_layers_params,
    )
    .mapvalues(argnames=["grouped_layers"], argvalues=generate_raster_layers)
)


# %% [markdown]
# ## Zip speedraster layers and zoom values

# %%
# parameters

speedraster_view_zip_params = dict()

# %%
# call the task


speedraster_view_zip = (
    zip_grouped_by_key.set_task_instance_id("speedraster_view_zip")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=combine_seasonal_raster_layers,
        right=zoom_speedraster_view,
        **speedraster_view_zip_params,
    )
    .call()
)


# %% [markdown]
# ## Draw speedraster ecomaps by group

# %%
# parameters

draw_speed_raster_ecomaps_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_speed_raster_ecomaps = (
    draw_ecomap.set_task_instance_id("draw_speed_raster_ecomaps")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "Mean Speed Value (km/h)"},
        static=False,
        title=None,
        max_zoom=12,
        **draw_speed_raster_ecomaps_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=speedraster_view_zip)
)


# %% [markdown]
# ## Persist speedraster ecomap HTML paths

# %%
# parameters

speed_raster_ecomap_urls_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


speed_raster_ecomap_urls = (
    persist_text.set_task_instance_id("speed_raster_ecomap_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **speed_raster_ecomap_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=draw_speed_raster_ecomaps)
)


# %% [markdown]
# ## Create speedraster ecomap widgets

# %%
# parameters

speed_raster_ecomap_widgets_params = dict()

# %%
# call the task


speed_raster_ecomap_widgets = (
    create_map_widget_single_view.set_task_instance_id("speed_raster_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Speed Raster Ecomap", **speed_raster_ecomap_widgets_params)
    .map(argnames=["view", "data"], argvalues=speed_raster_ecomap_urls)
)


# %% [markdown]
# ## Merge speed raster ecomap widgets

# %%
# parameters

speedraster_ecomap_widgets_params = dict()

# %%
# call the task


speedraster_ecomap_widgets = (
    merge_widget_views.set_task_instance_id("speedraster_ecomap_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=speed_raster_ecomap_widgets, **speedraster_ecomap_widgets_params)
    .call()
)


# %% [markdown]
# ## Calculate seasonal home range

# %%
# parameters

seasonal_home_range_params = dict()

# %%
# call the task


seasonal_home_range = (
    calculate_seasonal_home_range.set_task_instance_id("seasonal_home_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        groupby_cols=["season"],
        percentiles=[99.9],
        auto_scale_or_custom_cell_size={
            "auto_scale_or_custom": "Customize",
            "grid_cell_size": 2000,
        },
        **seasonal_home_range_params,
    )
    .mapvalues(argnames=["gdf"], argvalues=add_season_labels)
)


# %% [markdown]
# ## Time density colormap

# %%
# parameters

season_colormap_params = dict()

# %%
# call the task


season_colormap = (
    apply_color_map.set_task_instance_id("season_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="season",
        output_column_name="season_colormap",
        colormap=["#f57c00", "#255084"],
        **season_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=seasonal_home_range)
)


# %% [markdown]
# ## Create map layers from seasons

# %%
# parameters

season_etd_map_layer_params = dict(
    zoom=...,
)

# %%
# call the task


season_etd_map_layer = (
    create_polygon_layer.set_task_instance_id("season_etd_map_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"fill_color_column": "season_colormap", "opacity": 0.65},
        legend={"label_column": "season", "color_column": "season_colormap"},
        tooltip_columns=["percentile"],
        **season_etd_map_layer_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=season_colormap)
)


# %% [markdown]
# ## Zoom seasons by view state

# %%
# parameters

zoom_season_view_params = dict()

# %%
# call the task


zoom_season_view = (
    create_view_state_from_gdf.set_task_instance_id("zoom_season_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, **zoom_season_view_params)
    .mapvalues(argnames=["gdf"], argvalues=season_colormap)
)


# %% [markdown]
# ## Combine map layers

# %%
# parameters

comb_season_map_layers_params = dict()

# %%
# call the task


comb_season_map_layers = (
    combine_map_layers.set_task_instance_id("comb_season_map_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        static_layers=[create_styled_landdx_layers, custom_text_layer],
        **comb_season_map_layers_params,
    )
    .mapvalues(argnames=["grouped_layers"], argvalues=season_etd_map_layer)
)


# %% [markdown]
# ## Zip seasons layers and zoom values

# %%
# parameters

seasons_view_zip_params = dict()

# %%
# call the task


seasons_view_zip = (
    zip_grouped_by_key.set_task_instance_id("seasons_view_zip")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=comb_season_map_layers, right=zoom_season_view, **seasons_view_zip_params
    )
    .call()
)


# %% [markdown]
# ## Draw season ecomap

# %%
# parameters

seasonal_ecomap_params = dict(
    widget_id=...,
)

# %%
# call the task


seasonal_ecomap = (
    draw_ecomap.set_task_instance_id("seasonal_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "Seasons"},
        static=False,
        title=None,
        max_zoom=12,
        **seasonal_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=seasons_view_zip)
)


# %% [markdown]
# ## Perist season ecomap as text

# %%
# parameters

season_etd_ecomap_html_url_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


season_etd_ecomap_html_url = (
    persist_text.set_task_instance_id("season_etd_ecomap_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **season_etd_ecomap_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=seasonal_ecomap)
)


# %% [markdown]
# ## Create map widgets for trajectories

# %%
# parameters

season_etd_widgets_single_view_params = dict()

# %%
# call the task


season_etd_widgets_single_view = (
    create_map_widget_single_view.set_task_instance_id("season_etd_widgets_single_view")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Seasonal Home Range", **season_etd_widgets_single_view_params)
    .map(argnames=["view", "data"], argvalues=season_etd_ecomap_html_url)
)


# %% [markdown]
# ## Merge ecomap widgets

# %%
# parameters

season_grouped_map_widget_params = dict()

# %%
# call the task


season_grouped_map_widget = (
    merge_widget_views.set_task_instance_id("season_grouped_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=season_etd_widgets_single_view, **season_grouped_map_widget_params)
    .call()
)


# %% [markdown]
# ## Calculate total mcp area

# %%
# parameters

total_mcp_area_params = dict()

# %%
# call the task


total_mcp_area = (
    dataframe_column_sum.set_task_instance_id("total_mcp_area")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="area_km2", **total_mcp_area_params)
    .mapvalues(argnames=["df"], argvalues=calculate_mcp)
)


# %% [markdown]
# ## Round off mcp area to 2 decimal places

# %%
# parameters

round_mcp_area_params = dict()

# %%
# call the task


round_mcp_area = (
    round_off_values.set_task_instance_id("round_mcp_area")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(dp=2, **round_mcp_area_params)
    .mapvalues(argnames=["value"], argvalues=total_mcp_area)
)


# %% [markdown]
# ## Calculate total grid area

# %%
# parameters

total_grid_area_params = dict()

# %%
# call the task


total_grid_area = (
    dataframe_column_sum.set_task_instance_id("total_grid_area")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="area_sqkm", **total_grid_area_params)
    .mapvalues(argnames=["df"], argvalues=generate_etd)
)


# %% [markdown]
# ## Round off grid area to 2 decimal places

# %%
# parameters

round_grid_area_params = dict()

# %%
# call the task


round_grid_area = (
    round_off_values.set_task_instance_id("round_grid_area")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(dp=2, **round_grid_area_params)
    .mapvalues(argnames=["value"], argvalues=total_grid_area)
)


# %% [markdown]
# ## Create single value widgets for total MCP area per group

# %%
# parameters

total_mcp_sv_widgets_params = dict()

# %%
# call the task


total_mcp_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id("total_mcp_sv_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        title="Total MCP Area (Km2)", decimal_places=1, **total_mcp_sv_widgets_params
    )
    .map(argnames=["view", "data"], argvalues=round_mcp_area)
)


# %% [markdown]
# ## Merge per group total MCP area SV widgets

# %%
# parameters

total_mcp_grouped_sv_widget_params = dict()

# %%
# call the task


total_mcp_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("total_mcp_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=total_mcp_sv_widgets, **total_mcp_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Create single value widgets for total grid area per group

# %%
# parameters

total_grid_sv_widgets_params = dict()

# %%
# call the task


total_grid_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id("total_grid_sv_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        title="Total Grid Area(Km2)", decimal_places=1, **total_grid_sv_widgets_params
    )
    .map(argnames=["view", "data"], argvalues=round_grid_area)
)


# %% [markdown]
# ## Merge per group total grid area SV widgets

# %%
# parameters

total_grid_grouped_sv_widget_params = dict()

# %%
# call the task


total_grid_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("total_grid_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=total_grid_sv_widgets, **total_grid_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Determine subject gender

# %%
# parameters

subject_gender_params = dict()

# %%
# call the task


subject_gender = (
    dataframe_column_first_unique_str.set_task_instance_id("subject_gender")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="subject_sex", **subject_gender_params)
    .mapvalues(argnames=["df"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Create Single Value Widgets for subject gender per group

# %%
# parameters

gender_widgets_params = dict()

# %%
# call the task


gender_widgets = (
    create_text_widget_single_view.set_task_instance_id("gender_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Gender", **gender_widgets_params)
    .map(argnames=["view", "data"], argvalues=subject_gender)
)


# %% [markdown]
# ## Merge per group gender SV widgets

# %%
# parameters

gender_sv_widget_params = dict()

# %%
# call the task


gender_sv_widget = (
    merge_widget_views.set_task_instance_id("gender_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=gender_widgets, **gender_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Get report duration

# %%
# parameters

report_duration_params = dict()

# %%
# call the task


report_duration = (
    get_duration.set_task_instance_id("report_duration")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_range=time_range, time_unit="months", **report_duration_params)
    .call()
)


# %% [markdown]
# ## Round off report duration to 2 decimal_places

# %%
# parameters

round_report_duration_params = dict()

# %%
# call the task


round_report_duration = (
    round_off_values.set_task_instance_id("round_report_duration")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(dp=2, value=report_duration, **round_report_duration_params)
    .call()
)


# %% [markdown]
# ## Get subject name

# %%
# parameters

get_subject_name_params = dict()

# %%
# call the task


get_subject_name = (
    dataframe_column_first_unique_str.set_task_instance_id("get_subject_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="subject_name", **get_subject_name_params)
    .mapvalues(argnames=["df"], argvalues=assign_quarter_colors_traj)
)


# %% [markdown]
# ## Unique subjects on relocs

# %%
# parameters

unique_subjects_params = dict()

# %%
# call the task


unique_subjects = (
    dataframe_column_nunique.set_task_instance_id("unique_subjects")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=rename_traj_cols, column_name="subject_name", **unique_subjects_params)
    .call()
)


# %% [markdown]
# ## Create cover template context

# %%
# parameters

create_cover_template_context_params = dict()

# %%
# call the task


create_cover_template_context = (
    build_mapbook_report_template.set_task_instance_id("create_cover_template_context")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        count=unique_subjects,
        org_logo_path=download_logo_path,
        report_period=time_range,
        prepared_by="Ecoscope",
        **create_cover_template_context_params,
    )
    .call()
)


# %% [markdown]
# ## Persist context to cover template

# %%
# parameters

persist_context_cover_params = dict()

# %%
# call the task


persist_context_cover = (
    create_context_page.set_task_instance_id("persist_context_cover")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        logo_width_cm=4.5,
        logo_height_cm=1.93,
        template_path=download_mapbook_cover_page,
        output_directory=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        context=create_cover_template_context,
        filename=None,
        **persist_context_cover_params,
    )
    .call()
)


# %% [markdown]
# ## Convert speedmap html to png

# %%
# parameters

convert_speedmap_html_to_png_params = dict()

# %%
# call the task


convert_speedmap_html_to_png = (
    html_to_png.set_task_instance_id("convert_speedmap_html_to_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        config={"wait_for_timeout": 40000},
        **convert_speedmap_html_to_png_params,
    )
    .mapvalues(argnames=["html_path"], argvalues=persist_speed_ecomap_urls)
)


# %% [markdown]
# ## Convert day/night html to png

# %%
# parameters

convert_day_night_html_to_png_params = dict()

# %%
# call the task


convert_day_night_html_to_png = (
    html_to_png.set_task_instance_id("convert_day_night_html_to_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        config={"wait_for_timeout": 40000},
        **convert_day_night_html_to_png_params,
    )
    .mapvalues(argnames=["html_path"], argvalues=persist_day_night_ecomap_urls)
)


# %% [markdown]
# ## Convert quarter html to png

# %%
# parameters

convert_quarter_html_to_png_params = dict()

# %%
# call the task


convert_quarter_html_to_png = (
    html_to_png.set_task_instance_id("convert_quarter_html_to_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        config={"wait_for_timeout": 40000},
        **convert_quarter_html_to_png_params,
    )
    .mapvalues(argnames=["html_path"], argvalues=persist_quarter_ecomap_urls)
)


# %% [markdown]
# ## Convert home range html to png

# %%
# parameters

convert_hr_html_to_png_params = dict()

# %%
# call the task


convert_hr_html_to_png = (
    html_to_png.set_task_instance_id("convert_hr_html_to_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        config={"wait_for_timeout": 40000},
        **convert_hr_html_to_png_params,
    )
    .mapvalues(argnames=["html_path"], argvalues=persist_hr_ecomap_urls)
)


# %% [markdown]
# ## Convert speed raster html to png

# %%
# parameters

convert_speed_raster_html_to_png_params = dict()

# %%
# call the task


convert_speed_raster_html_to_png = (
    html_to_png.set_task_instance_id("convert_speed_raster_html_to_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        config={"wait_for_timeout": 40000},
        **convert_speed_raster_html_to_png_params,
    )
    .mapvalues(argnames=["html_path"], argvalues=speed_raster_ecomap_urls)
)


# %% [markdown]
# ## Convert seasonal home range html to png

# %%
# parameters

convert_seasonal_hr_html_to_png_params = dict()

# %%
# call the task


convert_seasonal_hr_html_to_png = (
    html_to_png.set_task_instance_id("convert_seasonal_hr_html_to_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        config={"wait_for_timeout": 40000},
        **convert_seasonal_hr_html_to_png_params,
    )
    .mapvalues(argnames=["html_path"], argvalues=season_etd_ecomap_html_url)
)


# %% [markdown]
# ## Zip grid and mcp

# %%
# parameters

zip_grid_mcp_params = dict()

# %%
# call the task


zip_grid_mcp = (
    zip_grouped_by_key.set_task_instance_id("zip_grid_mcp")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(left=round_grid_area, right=round_mcp_area, **zip_grid_mcp_params)
    .call()
)


# %% [markdown]
# ## Zip with quarter png

# %%
# parameters

zip_grid_mcp_quarter_params = dict()

# %%
# call the task


zip_grid_mcp_quarter = (
    zip_grouped_by_key.set_task_instance_id("zip_grid_mcp_quarter")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_grid_mcp,
        right=convert_quarter_html_to_png,
        **zip_grid_mcp_quarter_params,
    )
    .call()
)


# %% [markdown]
# ## Zip with hr png

# %%
# parameters

zip_grid_mcp_quarter_hr_params = dict()

# %%
# call the task


zip_grid_mcp_quarter_hr = (
    zip_grouped_by_key.set_task_instance_id("zip_grid_mcp_quarter_hr")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_grid_mcp_quarter,
        right=convert_hr_html_to_png,
        **zip_grid_mcp_quarter_hr_params,
    )
    .call()
)


# %% [markdown]
# ## Zip with speed raster png

# %%
# parameters

zip_grid_mcp_speedraster_params = dict()

# %%
# call the task


zip_grid_mcp_speedraster = (
    zip_grouped_by_key.set_task_instance_id("zip_grid_mcp_speedraster")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_grid_mcp_quarter_hr,
        right=convert_speed_raster_html_to_png,
        **zip_grid_mcp_speedraster_params,
    )
    .call()
)


# %% [markdown]
# ## Zip with day/night png

# %%
# parameters

zip_grid_mcp_dn_params = dict()

# %%
# call the task


zip_grid_mcp_dn = (
    zip_grouped_by_key.set_task_instance_id("zip_grid_mcp_dn")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_grid_mcp_speedraster,
        right=convert_day_night_html_to_png,
        **zip_grid_mcp_dn_params,
    )
    .call()
)


# %% [markdown]
# ## Zip with speedmap png

# %%
# parameters

zip_grid_dn_speedmap_params = dict()

# %%
# call the task


zip_grid_dn_speedmap = (
    zip_grouped_by_key.set_task_instance_id("zip_grid_dn_speedmap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_grid_mcp_dn,
        right=convert_speedmap_html_to_png,
        **zip_grid_dn_speedmap_params,
    )
    .call()
)


# %% [markdown]
# ## Zip with seasonal hr png (final)

# %%
# parameters

zip_all_mapbook_context_inputs_params = dict()

# %%
# call the task


zip_all_mapbook_context_inputs = (
    zip_grouped_by_key.set_task_instance_id("zip_all_mapbook_context_inputs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_grid_dn_speedmap,
        right=convert_seasonal_hr_html_to_png,
        **zip_all_mapbook_context_inputs_params,
    )
    .call()
)


# %% [markdown]
# ## Zip with subject name

# %%
# parameters

zip_all_with_name_params = dict()

# %%
# call the task


zip_all_with_name = (
    zip_grouped_by_key.set_task_instance_id("zip_all_with_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=zip_all_mapbook_context_inputs,
        right=get_subject_name,
        **zip_all_with_name_params,
    )
    .call()
)


# %% [markdown]
# ## Flatten zipped mapbook context inputs

# %%
# parameters

flatten_mbook_context_params = dict()

# %%
# call the task


flatten_mbook_context = (
    flatten_tuple.set_task_instance_id("flatten_mbook_context")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**flatten_mbook_context_params)
    .mapvalues(argnames=["nested"], argvalues=zip_all_with_name)
)


# %% [markdown]
# ## Get split group names

# %%
# parameters

get_grouper_names_params = dict()

# %%
# call the task


get_grouper_names = (
    get_split_group_names.set_task_instance_id("get_grouper_names")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(split_data=split_trajectories_by_group, **get_grouper_names_params)
    .call()
)


# %% [markdown]
# ## Zip grouper names with flattened context

# %%
# parameters

zip_grouper_with_context_params = dict()

# %%
# call the task


zip_grouper_with_context = (
    zip_lists.set_task_instance_id("zip_grouper_with_context")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        left=get_grouper_names,
        right=flatten_mbook_context,
        **zip_grouper_with_context_params,
    )
    .call()
)


# %% [markdown]
# ## Flatten final report context

# %%
# parameters

flatten_final_report_context_params = dict()

# %%
# call the task


flatten_final_report_context = (
    flatten_tuple.set_task_instance_id("flatten_final_report_context")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**flatten_final_report_context_params)
    .mapvalues(argnames=["nested"], argvalues=zip_grouper_with_context)
)


# %% [markdown]
# ## Prepare mapbook context

# %%
# parameters

prepare_mapbook_context_params = dict()

# %%
# call the task


prepare_mapbook_context = (
    create_report_context_from_tuple.set_task_instance_id("prepare_mapbook_context")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**prepare_mapbook_context_params)
    .mapvalues(
        argnames=[
            "grouper_type",
            "grouper_eq",
            "grouper_value",
            "grid_area",
            "mcp_area",
            "movement_tracks_ecomap",
            "home_range_ecomap",
            "speed_raster_ecomap",
            "night_day_ecomap",
            "speedmap",
            "seasonal_homerange",
            "subject_name",
        ],
        argvalues=flatten_final_report_context,
    )
)


# %% [markdown]
# ## Create individual mapbook context

# %%
# parameters

individual_mapbook_context_params = dict()

# %%
# call the task


individual_mapbook_context = (
    create_mapbook_context.set_task_instance_id("individual_mapbook_context")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        template_path=download_sect_templates,
        output_directory=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        time_period=time_range,
        period=round_report_duration,
        filename=None,
        validate_images=True,
        box_h_cm=6.5,
        box_w_cm=11.11,
        **individual_mapbook_context_params,
    )
    .mapvalues(argnames=["context"], argvalues=prepare_mapbook_context)
)


# %% [markdown]
# ## Generate final mapbook report

# %%
# parameters

generate_mapbook_report_params = dict()

# %%
# call the task


generate_mapbook_report = (
    merge_docx_files.set_task_instance_id("generate_mapbook_report")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        cover_page_path=persist_context_cover,
        output_directory=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        context_page_items=individual_mapbook_context,
        filename="mapbook_report.docx",
        **generate_mapbook_report_params,
    )
    .call()
)


# %% [markdown]
# ## Mapbook dashboard

# %%
# parameters

mapbook_dashboard_params = dict(
    warning=...,
)

# %%
# call the task


mapbook_dashboard = (
    gather_dashboard.set_task_instance_id("mapbook_dashboard")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        details=initialize_workflow_metadata,
        widgets=[
            gender_sv_widget,
            total_mcp_grouped_sv_widget,
            total_grid_grouped_sv_widget,
            merge_speedmap_widgets,
            merge_day_night_ecomap_widgets,
            merge_quarter_ecomap_widgets,
            merge_hr_ecomap_widgets,
            speedraster_ecomap_widgets,
            season_grouped_map_widget,
        ],
        time_range=time_range,
        groupers=groupers,
        **mapbook_dashboard_params,
    )
    .call()
)
