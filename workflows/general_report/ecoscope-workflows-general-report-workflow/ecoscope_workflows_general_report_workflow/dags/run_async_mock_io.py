# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details

# ruff: noqa: E402

"""WARNING: This file is generated in a testing context and should not be used in production.
Lines specific to the testing context are marked with a test tube emoji (ðŸ§ª) to indicate
that they would not be included (or would be different) in the production version of this file.
"""

import json
import os
import warnings  # ðŸ§ª

from ecoscope_workflows_core.graph import DependsOn, Graph, Node
from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.io import set_gee_connection as set_gee_connection
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.testing import create_task_magicmock  # ðŸ§ª
from ecoscope_workflows_ext_custom.tasks.results import (
    set_base_maps_pydeck as set_base_maps_pydeck,
)
from ecoscope_workflows_ext_ste.tasks import (
    determine_previous_period as determine_previous_period,
)

get_subjectgroup_observations = create_task_magicmock(  # ðŸ§ª
    anchor="ecoscope_workflows_ext_ecoscope.tasks.io",  # ðŸ§ª
    func_name="get_subjectgroup_observations",  # ðŸ§ª
)  # ðŸ§ª
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_ext_custom.tasks.io import load_df as load_df
from ecoscope_workflows_ext_custom.tasks.transformation import (
    filter_row_values as filter_row_values,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    process_relocations as process_relocations,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory as relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    classify_is_night as classify_is_night,
)
from ecoscope_workflows_ext_ste.tasks import (
    annotate_gdf_dict_with_geom_type as annotate_gdf_dict_with_geom_type,
)
from ecoscope_workflows_ext_ste.tasks import (
    create_custom_text_layer as create_custom_text_layer,
)
from ecoscope_workflows_ext_ste.tasks import (
    create_deckgl_layers_from_gdf_dict as create_deckgl_layers_from_gdf_dict,
)
from ecoscope_workflows_ext_ste.tasks import (
    custom_trajectory_segment_filter as custom_trajectory_segment_filter,
)
from ecoscope_workflows_ext_ste.tasks import filter_df_cols as filter_df_cols
from ecoscope_workflows_ext_ste.tasks import get_file_path as get_file_path
from ecoscope_workflows_ext_ste.tasks import split_gdf_by_column as split_gdf_by_column

get_subjectgroup_observations = create_task_magicmock(  # ðŸ§ª
    anchor="ecoscope_workflows_ext_ecoscope.tasks.io",  # ðŸ§ª
    func_name="get_subjectgroup_observations",  # ðŸ§ª
)  # ðŸ§ª
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_core.tasks.transformation import sort_values as sort_values
from ecoscope_workflows_ext_custom.tasks.results import (
    create_path_layer as create_path_layer,
)
from ecoscope_workflows_ext_custom.tasks.results import draw_map as draw_map
from ecoscope_workflows_ext_ecoscope.tasks.io import persist_df as persist_df
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_classification as apply_classification,
)
from ecoscope_workflows_ext_ste.tasks import (
    combine_deckgl_map_layers as combine_deckgl_map_layers,
)
from ecoscope_workflows_ext_ste.tasks import create_column as create_column
from ecoscope_workflows_ext_ste.tasks import merge_multiple_df as merge_multiple_df
from ecoscope_workflows_ext_ste.tasks import (
    modify_status_colors as modify_status_colors,
)
from ecoscope_workflows_ext_ste.tasks import view_state_deck_gdf as view_state_deck_gdf

get_events = create_task_magicmock(  # ðŸ§ª
    anchor="ecoscope_workflows_ext_ecoscope.tasks.io",  # ðŸ§ª
    func_name="get_events",  # ðŸ§ª
)  # ðŸ§ª
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_ext_custom.tasks.results import (
    create_geojson_layer as create_geojson_layer,
)
from ecoscope_workflows_ext_custom.tasks.results import (
    create_scatterplot_layer as create_scatterplot_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    calculate_elliptical_time_density as calculate_elliptical_time_density,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ste.tasks import convert_hex_to_rgba as convert_hex_to_rgba
from ecoscope_workflows_ext_ste.tasks import (
    create_seasonal_labels as create_seasonal_labels,
)
from ecoscope_workflows_ext_ste.tasks import (
    custom_determine_season_windows as custom_determine_season_windows,
)
from ecoscope_workflows_ext_ste.tasks import filter_df_values as filter_df_values
from ecoscope_workflows_ext_ste.tasks import (
    generate_ecograph_raster as generate_ecograph_raster,
)
from ecoscope_workflows_ext_ste.tasks import (
    retrieve_feature_gdf as retrieve_feature_gdf,
)

from ..params import Params


def main(params: Params):
    warnings.warn("This test script should not be used in production!")  # ðŸ§ª

    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    dependencies = {
        "workflow_details": [],
        "time_range": [],
        "groupers": [],
        "configure_base_maps": [],
        "set_previous_period": ["time_range"],
        "er_client_name": [],
        "gee_project_name": [],
        "subject_group_var": [],
        "subject_observations": ["er_client_name", "time_range", "subject_group_var"],
        "retrieve_ldx_db": [],
        "load_ldx": ["retrieve_ldx_db"],
        "filter_ldx_aoi": ["load_ldx"],
        "filter_ldx_cols": ["filter_ldx_aoi"],
        "create_ldx_text_layer": ["filter_ldx_cols"],
        "split_ldx_by_type": ["filter_ldx_cols"],
        "annotate_gdf_dict": ["split_ldx_by_type"],
        "create_ldx_styled_layers": ["annotate_gdf_dict"],
        "subject_reloc": ["subject_observations"],
        "annotate_day_night": ["subject_reloc"],
        "custom_trajs_filter": [],
        "convert_to_trajectories": ["annotate_day_night", "custom_trajs_filter"],
        "add_temporal_index_to_traj": ["convert_to_trajectories", "groupers"],
        "previous_observations": [
            "er_client_name",
            "set_previous_period",
            "subject_group_var",
        ],
        "previous_relocs": ["previous_observations"],
        "annotate_prev_day_night": ["previous_relocs"],
        "convert_prev_to_trajectories": [
            "annotate_prev_day_night",
            "custom_trajs_filter",
        ],
        "add_temporal_prev_index_to_traj": ["convert_prev_to_trajectories", "groupers"],
        "rename_prev_traj_cols": ["add_temporal_prev_index_to_traj"],
        "classify_trajectories_speed_bins": ["add_temporal_index_to_traj"],
        "rename_traj_cols": ["classify_trajectories_speed_bins"],
        "persist_trajs_geoparquet": ["rename_traj_cols"],
        "persist_prev_trajs_geoparquet": ["rename_prev_traj_cols"],
        "persist_relocs_geoparquet": ["subject_reloc"],
        "persist_prev_relocs_geoparquet": ["previous_relocs"],
        "create_current_duration_column": ["rename_traj_cols"],
        "create_previous_duration_column": ["rename_prev_traj_cols"],
        "merge_current_prev_trajs": [
            "create_current_duration_column",
            "create_previous_duration_column",
        ],
        "assign_duration_colors": ["merge_current_prev_trajs"],
        "sort_trajs_by_status": ["assign_duration_colors"],
        "filter_movement_cols": ["sort_trajs_by_status"],
        "generate_track_layers": ["filter_movement_cols"],
        "combined_ldx_movement_layers": [
            "create_ldx_styled_layers",
            "create_ldx_text_layer",
            "generate_track_layers",
        ],
        "movement_view_state": ["filter_movement_cols"],
        "draw_movement_tracks": [
            "configure_base_maps",
            "movement_view_state",
            "combined_ldx_movement_layers",
        ],
        "persist_movement_tracks_html": ["draw_movement_tracks"],
        "get_events_data": ["er_client_name", "time_range"],
        "generate_collaring_layers": ["get_events_data"],
        "combined_ldx_collar_points": [
            "create_ldx_styled_layers",
            "create_ldx_text_layer",
            "generate_collaring_layers",
        ],
        "collaring_view_state": ["get_events_data"],
        "draw_collared_map": [
            "configure_base_maps",
            "collaring_view_state",
            "combined_ldx_collar_points",
        ],
        "persist_collared_points_html": ["draw_collared_map"],
        "convert_subject_hex_rgba": ["rename_traj_cols"],
        "generate_strack_layers": ["convert_subject_hex_rgba"],
        "combined_ldx_subject_layers": [
            "create_ldx_styled_layers",
            "create_ldx_text_layer",
            "generate_strack_layers",
        ],
        "tracks_view_state": ["convert_subject_hex_rgba"],
        "draw_subject_tracks": [
            "configure_base_maps",
            "tracks_view_state",
            "combined_ldx_subject_layers",
        ],
        "persist_subject_tracks_html": ["draw_subject_tracks"],
        "generate_etd": ["rename_traj_cols"],
        "persist_etd_gdf": ["generate_etd"],
        "determine_seasonal_windows": [
            "gee_project_name",
            "time_range",
            "generate_etd",
        ],
        "persist_ndvi_values": ["determine_seasonal_windows"],
        "add_season_labels": ["determine_seasonal_windows", "rename_traj_cols"],
        "apply_etd_colormap": ["generate_etd"],
        "generate_home_range_layers": ["apply_etd_colormap"],
        "combined_ldx_home_range_layers": [
            "create_ldx_styled_layers",
            "create_ldx_text_layer",
            "generate_home_range_layers",
        ],
        "overall_hr_view_state": ["apply_etd_colormap"],
        "draw_home_range_map": [
            "configure_base_maps",
            "combined_ldx_home_range_layers",
            "overall_hr_view_state",
        ],
        "persist_homerange_html": ["draw_home_range_map"],
        "filter_percentile": ["generate_etd"],
        "custom_home_range_layers": ["filter_percentile"],
        "combined_ldx_filtered_hr_layers": [
            "create_ldx_styled_layers",
            "create_ldx_text_layer",
            "custom_home_range_layers",
        ],
        "filtered_hr_view_state": ["filter_percentile"],
        "draw_filtered_hr_map": [
            "configure_base_maps",
            "combined_ldx_filtered_hr_layers",
            "filtered_hr_view_state",
        ],
        "persist_filtered_hr_html": ["draw_filtered_hr_map"],
        "generate_recursion_raster": ["add_season_labels"],
        "extract_raster": ["generate_recursion_raster"],
        "sort_recursion_features": ["extract_raster"],
        "classify_recursion_features": ["sort_recursion_features"],
        "apply_recursion_colormap": ["classify_recursion_features"],
        "generate_recursion_layers": ["apply_recursion_colormap"],
        "combined_ldx_recursion_layers": [
            "create_ldx_styled_layers",
            "create_ldx_text_layer",
            "generate_recursion_layers",
        ],
        "recursion_view_state": ["apply_recursion_colormap"],
        "draw_recursion_map": [
            "configure_base_maps",
            "combined_ldx_recursion_layers",
            "recursion_view_state",
        ],
        "persist_recursion_html": ["draw_recursion_map"],
        "persist_strajs_geoparquet": ["add_season_labels"],
        "persist_strajs_csv": ["add_season_labels"],
        "mapbook_dashboard": ["workflow_details", "time_range", "groupers"],
    }

    nodes = {
        "workflow_details": Node(
            async_task=set_workflow_details.validate()
            .set_task_instance_id("workflow_details")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("workflow_details") or {}),
            method="call",
        ),
        "time_range": Node(
            async_task=set_time_range.validate()
            .set_task_instance_id("time_range")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("time_range") or {}),
            method="call",
        ),
        "groupers": Node(
            async_task=set_groupers.validate()
            .set_task_instance_id("groupers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={} | (params_dict.get("groupers") or {}),
            method="call",
        ),
        "configure_base_maps": Node(
            async_task=set_base_maps_pydeck.validate()
            .set_task_instance_id("configure_base_maps")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "base_maps": [
                    {
                        "url": "https://server.arcgisonline.com/arcgis/rest/services/Elevation/World_Hillshade/MapServer/tile/{z}/{y}/{x}",
                        "opacity": 1,
                        "max_zoom": 20,
                    },
                ],
            }
            | (params_dict.get("configure_base_maps") or {}),
            method="call",
        ),
        "set_previous_period": Node(
            async_task=determine_previous_period.validate()
            .set_task_instance_id("set_previous_period")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "current_time_range": DependsOn("time_range"),
            }
            | (params_dict.get("set_previous_period") or {}),
            method="call",
        ),
        "er_client_name": Node(
            async_task=set_er_connection.validate()
            .set_task_instance_id("er_client_name")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("er_client_name") or {}),
            method="call",
        ),
        "gee_project_name": Node(
            async_task=set_gee_connection.validate()
            .set_task_instance_id("gee_project_name")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("gee_project_name") or {}),
            method="call",
        ),
        "subject_group_var": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("subject_group_var")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("subject_group_var") or {}),
            method="call",
        ),
        "subject_observations": Node(
            async_task=get_subjectgroup_observations.validate()
            .set_task_instance_id("subject_observations")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "filter": "clean",
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("time_range"),
                "subject_group_name": DependsOn("subject_group_var"),
                "raise_on_empty": False,
                "include_details": False,
                "include_subjectsource_details": False,
            }
            | (params_dict.get("subject_observations") or {}),
            method="call",
        ),
        "retrieve_ldx_db": Node(
            async_task=get_file_path.validate()
            .set_task_instance_id("retrieve_ldx_db")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "output_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("retrieve_ldx_db") or {}),
            method="call",
        ),
        "load_ldx": Node(
            async_task=load_df.validate()
            .set_task_instance_id("load_ldx")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "file_path": DependsOn("retrieve_ldx_db"),
                "layer": "landDx_polygons",
                "deserialize_json": False,
            }
            | (params_dict.get("load_ldx") or {}),
            method="call",
        ),
        "filter_ldx_aoi": Node(
            async_task=filter_row_values.validate()
            .set_task_instance_id("filter_ldx_aoi")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("load_ldx"),
                "column": "type",
                "values": [
                    "Community Conservancy",
                    "National Reserve",
                    "National Park",
                ],
            }
            | (params_dict.get("filter_ldx_aoi") or {}),
            method="call",
        ),
        "filter_ldx_cols": Node(
            async_task=filter_df_cols.validate()
            .set_task_instance_id("filter_ldx_cols")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("filter_ldx_aoi"),
                "columns": [
                    "type",
                    "name",
                    "geometry",
                ],
            }
            | (params_dict.get("filter_ldx_cols") or {}),
            method="call",
        ),
        "create_ldx_text_layer": Node(
            async_task=create_custom_text_layer.validate()
            .set_task_instance_id("create_ldx_text_layer")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "geodataframe": DependsOn("filter_ldx_cols"),
                "layer_style": {
                    "get_text": "name",
                    "get_color": [
                        20,
                        20,
                        20,
                        255,
                    ],
                    "get_size": 1000,
                    "size_units": "meters",
                    "size_min_pixels": 40,
                    "size_max_pixels": 75,
                    "size_scale": 1.25,
                    "font_family": "Arial",
                    "font_weight": "normal",
                    "get_text_anchor": "middle",
                    "get_alignment_baseline": "center",
                    "billboard": True,
                    "background_padding": [
                        4,
                        8,
                    ],
                    "pickable": True,
                    "auto_highlight": False,
                },
                "use_centroid": True,
                "legend": None,
            }
            | (params_dict.get("create_ldx_text_layer") or {}),
            method="call",
        ),
        "split_ldx_by_type": Node(
            async_task=split_gdf_by_column.validate()
            .set_task_instance_id("split_ldx_by_type")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("filter_ldx_cols"),
                "column": "type",
            }
            | (params_dict.get("split_ldx_by_type") or {}),
            method="call",
        ),
        "annotate_gdf_dict": Node(
            async_task=annotate_gdf_dict_with_geom_type.validate()
            .set_task_instance_id("annotate_gdf_dict")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf_dict": DependsOn("split_ldx_by_type"),
            }
            | (params_dict.get("annotate_gdf_dict") or {}),
            method="call",
        ),
        "create_ldx_styled_layers": Node(
            async_task=create_deckgl_layers_from_gdf_dict.validate()
            .set_task_instance_id("create_ldx_styled_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf_dict": DependsOn("annotate_gdf_dict"),
                "styles": {
                    "Community Conservancy": {
                        "get_fill_color": [
                            166,
                            182,
                            151,
                        ],
                        "get_line_color": [
                            166,
                            182,
                            151,
                        ],
                        "opacity": 0.175,
                        "stroked": True,
                        "get_line_width": 2.25,
                    },
                    "National Reserve": {
                        "get_fill_color": [
                            136,
                            167,
                            142,
                        ],
                        "get_line_color": [
                            136,
                            167,
                            142,
                        ],
                        "opacity": 0.175,
                        "stroked": True,
                        "get_line_width": 2.25,
                    },
                    "National Park": {
                        "get_fill_color": [
                            17,
                            86,
                            49,
                        ],
                        "get_line_color": [
                            17,
                            86,
                            49,
                        ],
                        "opacity": 0.175,
                        "stroked": True,
                        "get_line_width": 2.25,
                    },
                },
                "legends": {
                    "title": "Land Use",
                    "values": [
                        {
                            "label": "Community Conservancy",
                            "color": "#a6b697",
                        },
                        {
                            "label": "National Reserve",
                            "color": "#88a78e",
                        },
                        {
                            "label": "National Park",
                            "color": "#115631",
                        },
                    ],
                },
            }
            | (params_dict.get("create_ldx_styled_layers") or {}),
            method="call",
        ),
        "subject_reloc": Node(
            async_task=process_relocations.validate()
            .set_task_instance_id("subject_reloc")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "observations": DependsOn("subject_observations"),
                "relocs_columns": [
                    "groupby_col",
                    "fixtime",
                    "junk_status",
                    "geometry",
                    "extra__subject__name",
                    "extra__subject__hex",
                    "extra__subject__sex",
                    "extra__created_at",
                    "extra__subject__subject_subtype",
                ],
                "filter_point_coords": [
                    {
                        "x": 180.0,
                        "y": 90.0,
                    },
                    {
                        "x": 0.0,
                        "y": 0.0,
                    },
                    {
                        "x": 1.0,
                        "y": 1.0,
                    },
                ],
            }
            | (params_dict.get("subject_reloc") or {}),
            method="call",
        ),
        "annotate_day_night": Node(
            async_task=classify_is_night.validate()
            .set_task_instance_id("annotate_day_night")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("subject_reloc"),
            }
            | (params_dict.get("annotate_day_night") or {}),
            method="call",
        ),
        "custom_trajs_filter": Node(
            async_task=custom_trajectory_segment_filter.validate()
            .set_task_instance_id("custom_trajs_filter")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("custom_trajs_filter") or {}),
            method="call",
        ),
        "convert_to_trajectories": Node(
            async_task=relocations_to_trajectory.validate()
            .set_task_instance_id("convert_to_trajectories")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("annotate_day_night"),
                "trajectory_segment_filter": DependsOn("custom_trajs_filter"),
            }
            | (params_dict.get("convert_to_trajectories") or {}),
            method="call",
        ),
        "add_temporal_index_to_traj": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("add_temporal_index_to_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("convert_to_trajectories"),
                "time_col": "segment_start",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("add_temporal_index_to_traj") or {}),
            method="call",
        ),
        "previous_observations": Node(
            async_task=get_subjectgroup_observations.validate()
            .set_task_instance_id("previous_observations")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "filter": "clean",
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("set_previous_period"),
                "subject_group_name": DependsOn("subject_group_var"),
                "raise_on_empty": False,
                "include_details": False,
                "include_subjectsource_details": False,
            }
            | (params_dict.get("previous_observations") or {}),
            method="call",
        ),
        "previous_relocs": Node(
            async_task=process_relocations.validate()
            .set_task_instance_id("previous_relocs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "observations": DependsOn("previous_observations"),
                "relocs_columns": [
                    "groupby_col",
                    "fixtime",
                    "junk_status",
                    "geometry",
                    "extra__subject__name",
                    "extra__subject__hex",
                    "extra__subject__sex",
                    "extra__created_at",
                    "extra__subject__subject_subtype",
                ],
                "filter_point_coords": [
                    {
                        "x": 180.0,
                        "y": 90.0,
                    },
                    {
                        "x": 0.0,
                        "y": 0.0,
                    },
                    {
                        "x": 1.0,
                        "y": 1.0,
                    },
                ],
            }
            | (params_dict.get("previous_relocs") or {}),
            method="call",
        ),
        "annotate_prev_day_night": Node(
            async_task=classify_is_night.validate()
            .set_task_instance_id("annotate_prev_day_night")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("previous_relocs"),
            }
            | (params_dict.get("annotate_prev_day_night") or {}),
            method="call",
        ),
        "convert_prev_to_trajectories": Node(
            async_task=relocations_to_trajectory.validate()
            .set_task_instance_id("convert_prev_to_trajectories")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("annotate_prev_day_night"),
                "trajectory_segment_filter": DependsOn("custom_trajs_filter"),
            }
            | (params_dict.get("convert_prev_to_trajectories") or {}),
            method="call",
        ),
        "add_temporal_prev_index_to_traj": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("add_temporal_prev_index_to_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("convert_prev_to_trajectories"),
                "time_col": "segment_start",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("add_temporal_prev_index_to_traj") or {}),
            method="call",
        ),
        "rename_prev_traj_cols": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("rename_prev_traj_cols")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "raise_if_not_found": True,
                "df": DependsOn("add_temporal_prev_index_to_traj"),
                "rename_columns": {
                    "extra__hex": "hex_color",
                    "extra__is_night": "is_night",
                    "extra__name": "subject_name",
                    "extra__sex": "subject_sex",
                    "extra__subject_subtype": "subject_subtype",
                    "extra__created_at": "created_at",
                },
            }
            | (params_dict.get("rename_prev_traj_cols") or {}),
            method="call",
        ),
        "classify_trajectories_speed_bins": Node(
            async_task=apply_classification.validate()
            .set_task_instance_id("classify_trajectories_speed_bins")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("add_temporal_index_to_traj"),
                "input_column_name": "speed_kmhr",
                "output_column_name": "speed_bins",
                "classification_options": {
                    "scheme": "equal_interval",
                    "k": 6,
                },
                "label_options": {
                    "label_ranges": True,
                    "label_decimals": 1,
                    "label_suffix": " km/h",
                },
            }
            | (params_dict.get("classify_trajectories_speed_bins") or {}),
            method="call",
        ),
        "rename_traj_cols": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("rename_traj_cols")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "raise_if_not_found": True,
                "df": DependsOn("classify_trajectories_speed_bins"),
                "rename_columns": {
                    "extra__hex": "hex_color",
                    "extra__is_night": "is_night",
                    "extra__name": "subject_name",
                    "extra__sex": "subject_sex",
                    "extra__subject_subtype": "subject_subtype",
                    "extra__created_at": "created_at",
                },
            }
            | (params_dict.get("rename_traj_cols") or {}),
            method="call",
        ),
        "persist_trajs_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_trajs_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("rename_traj_cols"),
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "trajectories",
            }
            | (params_dict.get("persist_trajs_geoparquet") or {}),
            method="call",
        ),
        "persist_prev_trajs_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_prev_trajs_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("rename_prev_traj_cols"),
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "previous_period_trajectories",
            }
            | (params_dict.get("persist_prev_trajs_geoparquet") or {}),
            method="call",
        ),
        "persist_relocs_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_relocs_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("subject_reloc"),
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "relocations",
            }
            | (params_dict.get("persist_relocs_geoparquet") or {}),
            method="call",
        ),
        "persist_prev_relocs_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_prev_relocs_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("previous_relocs"),
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "previous_period_relocations",
            }
            | (params_dict.get("persist_prev_relocs_geoparquet") or {}),
            method="call",
        ),
        "create_current_duration_column": Node(
            async_task=create_column.validate()
            .set_task_instance_id("create_current_duration_column")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("rename_traj_cols"),
                "col_name": "duration_status",
                "value": "Current tracks",
            }
            | (params_dict.get("create_current_duration_column") or {}),
            method="call",
        ),
        "create_previous_duration_column": Node(
            async_task=create_column.validate()
            .set_task_instance_id("create_previous_duration_column")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("rename_prev_traj_cols"),
                "col_name": "duration_status",
                "value": "Previous tracks",
            }
            | (params_dict.get("create_previous_duration_column") or {}),
            method="call",
        ),
        "merge_current_prev_trajs": Node(
            async_task=merge_multiple_df.validate()
            .set_task_instance_id("merge_current_prev_trajs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "list_df": [
                    DependsOn("create_current_duration_column"),
                    DependsOn("create_previous_duration_column"),
                ],
                "ignore_index": True,
                "sort": False,
            }
            | (params_dict.get("merge_current_prev_trajs") or {}),
            method="call",
        ),
        "assign_duration_colors": Node(
            async_task=modify_status_colors.validate()
            .set_task_instance_id("assign_duration_colors")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "grouper_value": "overall",
                "gdf": DependsOn("merge_current_prev_trajs"),
            }
            | (params_dict.get("assign_duration_colors") or {}),
            method="call",
        ),
        "sort_trajs_by_status": Node(
            async_task=sort_values.validate()
            .set_task_instance_id("sort_trajs_by_status")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "duration_status",
                "na_position": "first",
                "ascending": False,
                "df": DependsOn("assign_duration_colors"),
            }
            | (params_dict.get("sort_trajs_by_status") or {}),
            method="call",
        ),
        "filter_movement_cols": Node(
            async_task=filter_df_cols.validate()
            .set_task_instance_id("filter_movement_cols")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "columns": [
                    "duration_status",
                    "duration_status_colors",
                    "is_night",
                    "geometry",
                ],
                "df": DependsOn("sort_trajs_by_status"),
            }
            | (params_dict.get("filter_movement_cols") or {}),
            method="call",
        ),
        "generate_track_layers": Node(
            async_task=create_path_layer.validate()
            .set_task_instance_id("generate_track_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_color": "duration_status_colors",
                    "get_width": 2.85,
                    "width_scale": 1,
                    "width_min_pixels": 2,
                    "width_max_pixels": 8,
                    "width_units": "pixels",
                    "cap_rounded": True,
                    "joint_rounded": True,
                    "billboard": False,
                    "opacity": 0.55,
                    "stroked": True,
                },
                "legend": {
                    "title": "Movement Tracks",
                    "label_column": "duration_status",
                    "color_column": "duration_status_colors",
                    "sort": "ascending",
                    "label_suffix": None,
                },
                "geodataframe": DependsOn("filter_movement_cols"),
            }
            | (params_dict.get("generate_track_layers") or {}),
            method="call",
        ),
        "combined_ldx_movement_layers": Node(
            async_task=combine_deckgl_map_layers.validate()
            .set_task_instance_id("combined_ldx_movement_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": [
                    DependsOn("create_ldx_styled_layers"),
                    DependsOn("create_ldx_text_layer"),
                ],
                "grouped_layers": DependsOn("generate_track_layers"),
            }
            | (params_dict.get("combined_ldx_movement_layers") or {}),
            method="call",
        ),
        "movement_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("movement_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("filter_movement_cols"),
                "pitch": 0,
                "bearing": 0,
            }
            | (params_dict.get("movement_view_state") or {}),
            method="call",
        ),
        "draw_movement_tracks": Node(
            async_task=draw_map.validate()
            .set_task_instance_id("draw_movement_tracks")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("configure_base_maps"),
                "static": False,
                "title": None,
                "max_zoom": 10,
                "legend_style": {
                    "placement": "bottom-right",
                },
                "view_state": DependsOn("movement_view_state"),
                "geo_layers": DependsOn("combined_ldx_movement_layers"),
            }
            | (params_dict.get("draw_movement_tracks") or {}),
            method="call",
        ),
        "persist_movement_tracks_html": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("persist_movement_tracks_html")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "movement_tracks",
                "text": DependsOn("draw_movement_tracks"),
            }
            | (params_dict.get("persist_movement_tracks_html") or {}),
            method="call",
        ),
        "get_events_data": Node(
            async_task=get_events.validate()
            .set_task_instance_id("get_events_data")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("time_range"),
                "event_columns": [
                    "id",
                    "time",
                    "event_type",
                    "event_category",
                    "reported_by",
                    "serial_number",
                    "geometry",
                    "created_at",
                    "event_details",
                ],
                "raise_on_empty": False,
                "include_details": True,
                "include_updates": False,
                "include_related_events": False,
                "include_null_geometry": False,
                "include_display_values": False,
            }
            | (params_dict.get("get_events_data") or {}),
            method="call",
        ),
        "generate_collaring_layers": Node(
            async_task=create_scatterplot_layer.validate()
            .set_task_instance_id("generate_collaring_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_fill_color": [
                        85,
                        107,
                        47,
                    ],
                    "get_line_color": [
                        0,
                        0,
                        0,
                        200,
                    ],
                    "get_line_width": 0.55,
                    "get_radius": 3.55,
                    "opacity": 0.75,
                    "stroked": True,
                },
                "legend": {
                    "title": "Legend",
                    "values": [
                        {
                            "label": "Elephant sightings",
                            "color": "#556b2f",
                        },
                    ],
                },
                "geodataframe": DependsOn("get_events_data"),
            }
            | (params_dict.get("generate_collaring_layers") or {}),
            method="call",
        ),
        "combined_ldx_collar_points": Node(
            async_task=combine_deckgl_map_layers.validate()
            .set_task_instance_id("combined_ldx_collar_points")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": [
                    DependsOn("create_ldx_styled_layers"),
                    DependsOn("create_ldx_text_layer"),
                ],
                "grouped_layers": DependsOn("generate_collaring_layers"),
            }
            | (params_dict.get("combined_ldx_collar_points") or {}),
            method="call",
        ),
        "collaring_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("collaring_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("get_events_data"),
                "pitch": 0,
                "bearing": 0,
            }
            | (params_dict.get("collaring_view_state") or {}),
            method="call",
        ),
        "draw_collared_map": Node(
            async_task=draw_map.validate()
            .set_task_instance_id("draw_collared_map")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("configure_base_maps"),
                "static": False,
                "title": None,
                "max_zoom": 10,
                "legend_style": {
                    "placement": "bottom-right",
                },
                "view_state": DependsOn("collaring_view_state"),
                "geo_layers": DependsOn("combined_ldx_collar_points"),
            }
            | (params_dict.get("draw_collared_map") or {}),
            method="call",
        ),
        "persist_collared_points_html": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("persist_collared_points_html")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "collared_points",
                "text": DependsOn("draw_collared_map"),
            }
            | (params_dict.get("persist_collared_points_html") or {}),
            method="call",
        ),
        "convert_subject_hex_rgba": Node(
            async_task=convert_hex_to_rgba.validate()
            .set_task_instance_id("convert_subject_hex_rgba")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("rename_traj_cols"),
                "col": "hex_color",
                "new_col": "rgba_colors",
            }
            | (params_dict.get("convert_subject_hex_rgba") or {}),
            method="call",
        ),
        "generate_strack_layers": Node(
            async_task=create_path_layer.validate()
            .set_task_instance_id("generate_strack_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_color": "rgba_colors",
                    "get_width": 2.85,
                    "width_scale": 1,
                    "width_min_pixels": 2,
                    "width_max_pixels": 8,
                    "width_units": "pixels",
                    "cap_rounded": True,
                    "joint_rounded": True,
                    "billboard": False,
                    "opacity": 0.55,
                    "stroked": True,
                },
                "legend": {
                    "title": "Movement Tracks",
                    "label_column": "subject_name",
                    "color_column": "rgba_colors",
                    "sort": "ascending",
                    "label_suffix": None,
                },
                "geodataframe": DependsOn("convert_subject_hex_rgba"),
            }
            | (params_dict.get("generate_strack_layers") or {}),
            method="call",
        ),
        "combined_ldx_subject_layers": Node(
            async_task=combine_deckgl_map_layers.validate()
            .set_task_instance_id("combined_ldx_subject_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": [
                    DependsOn("create_ldx_styled_layers"),
                    DependsOn("create_ldx_text_layer"),
                ],
                "grouped_layers": DependsOn("generate_strack_layers"),
            }
            | (params_dict.get("combined_ldx_subject_layers") or {}),
            method="call",
        ),
        "tracks_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("tracks_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("convert_subject_hex_rgba"),
                "pitch": 0,
                "bearing": 0,
            }
            | (params_dict.get("tracks_view_state") or {}),
            method="call",
        ),
        "draw_subject_tracks": Node(
            async_task=draw_map.validate()
            .set_task_instance_id("draw_subject_tracks")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("configure_base_maps"),
                "static": False,
                "title": None,
                "max_zoom": 10,
                "legend_style": {
                    "placement": "bottom-right",
                },
                "view_state": DependsOn("tracks_view_state"),
                "geo_layers": DependsOn("combined_ldx_subject_layers"),
            }
            | (params_dict.get("draw_subject_tracks") or {}),
            method="call",
        ),
        "persist_subject_tracks_html": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("persist_subject_tracks_html")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "subject_tracks",
                "text": DependsOn("draw_subject_tracks"),
            }
            | (params_dict.get("persist_subject_tracks_html") or {}),
            method="call",
        ),
        "generate_etd": Node(
            async_task=calculate_elliptical_time_density.validate()
            .set_task_instance_id("generate_etd")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "auto_scale_or_custom_cell_size": {
                    "auto_scale_or_customize": "Auto-scale",
                },
                "crs": "ESRI:53042",
                "percentiles": [
                    50.0,
                    60.0,
                    70.0,
                    80.0,
                    90.0,
                    95.0,
                    99.9,
                ],
                "nodata_value": "nan",
                "band_count": 1,
                "max_speed_factor": 1.05,
                "expansion_factor": 1.3,
                "trajectory_gdf": DependsOn("rename_traj_cols"),
            }
            | (params_dict.get("generate_etd") or {}),
            method="call",
        ),
        "persist_etd_gdf": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_etd_gdf")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "geoparquet",
                "filename": "home_range_etd",
                "df": DependsOn("generate_etd"),
            }
            | (params_dict.get("persist_etd_gdf") or {}),
            method="call",
        ),
        "determine_seasonal_windows": Node(
            async_task=custom_determine_season_windows.validate()
            .set_task_instance_id("determine_seasonal_windows")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("gee_project_name"),
                "time_range": DependsOn("time_range"),
                "roi": DependsOn("generate_etd"),
            }
            | (params_dict.get("determine_seasonal_windows") or {}),
            method="call",
        ),
        "persist_ndvi_values": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_ndvi_values")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "csv",
                "filename": "seasonal_windows",
                "df": DependsOn("determine_seasonal_windows"),
            }
            | (params_dict.get("persist_ndvi_values") or {}),
            method="call",
        ),
        "add_season_labels": Node(
            async_task=create_seasonal_labels.validate()
            .set_task_instance_id("add_season_labels")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "seasons_df": DependsOn("determine_seasonal_windows"),
                "trajectories": DependsOn("rename_traj_cols"),
            }
            | (params_dict.get("add_season_labels") or {}),
            method="call",
        ),
        "apply_etd_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("apply_etd_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "input_column_name": "percentile",
                "output_column_name": "etd_percentile_colors",
                "colormap": "RdYlGn",
                "df": DependsOn("generate_etd"),
            }
            | (params_dict.get("apply_etd_colormap") or {}),
            method="call",
        ),
        "generate_home_range_layers": Node(
            async_task=create_geojson_layer.validate()
            .set_task_instance_id("generate_home_range_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "filled": True,
                    "stroked": True,
                    "extruded": False,
                    "wireframe": False,
                    "get_fill_color": "etd_percentile_colors",
                    "get_line_color": "etd_percentile_colors",
                    "opacity": 0.55,
                    "get_line_width": 1.55,
                    "get_elevation": 0,
                    "get_point_radius": 1,
                    "line_width_units": "pixels",
                    "line_width_scale": 1,
                    "line_width_min_pixels": 1,
                    "line_width_max_pixels": 5,
                },
                "legend": {
                    "title": "Home Range Percentiles",
                    "label_column": "percentile",
                    "color_column": "etd_percentile_colors",
                    "sort": "ascending",
                    "label_suffix": None,
                },
                "geodataframe": DependsOn("apply_etd_colormap"),
            }
            | (params_dict.get("generate_home_range_layers") or {}),
            method="call",
        ),
        "combined_ldx_home_range_layers": Node(
            async_task=combine_deckgl_map_layers.validate()
            .set_task_instance_id("combined_ldx_home_range_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": [
                    DependsOn("create_ldx_styled_layers"),
                    DependsOn("create_ldx_text_layer"),
                ],
                "grouped_layers": DependsOn("generate_home_range_layers"),
            }
            | (params_dict.get("combined_ldx_home_range_layers") or {}),
            method="call",
        ),
        "overall_hr_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("overall_hr_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("apply_etd_colormap"),
                "pitch": 0,
                "bearing": 0,
            }
            | (params_dict.get("overall_hr_view_state") or {}),
            method="call",
        ),
        "draw_home_range_map": Node(
            async_task=draw_map.validate()
            .set_task_instance_id("draw_home_range_map")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("configure_base_maps"),
                "static": False,
                "title": None,
                "max_zoom": 10,
                "legend_style": {
                    "placement": "bottom-right",
                },
                "geo_layers": DependsOn("combined_ldx_home_range_layers"),
                "view_state": DependsOn("overall_hr_view_state"),
            }
            | (params_dict.get("draw_home_range_map") or {}),
            method="call",
        ),
        "persist_homerange_html": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("persist_homerange_html")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "overall_homerange",
                "text": DependsOn("draw_home_range_map"),
            }
            | (params_dict.get("persist_homerange_html") or {}),
            method="call",
        ),
        "filter_percentile": Node(
            async_task=filter_df_values.validate()
            .set_task_instance_id("filter_percentile")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "percentile",
                "op": "ge",
                "value": 99.0,
                "df": DependsOn("generate_etd"),
                "reset_index": True,
            }
            | (params_dict.get("filter_percentile") or {}),
            method="call",
        ),
        "custom_home_range_layers": Node(
            async_task=create_geojson_layer.validate()
            .set_task_instance_id("custom_home_range_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "filled": True,
                    "stroked": True,
                    "extruded": False,
                    "wireframe": False,
                    "get_fill_color": [
                        210,
                        105,
                        30,
                    ],
                    "get_line_color": [
                        210,
                        105,
                        30,
                    ],
                    "opacity": 0.55,
                    "get_line_width": 1.55,
                    "get_elevation": 0,
                    "get_point_radius": 1,
                    "line_width_units": "pixels",
                    "line_width_scale": 1,
                    "line_width_min_pixels": 1,
                    "line_width_max_pixels": 5,
                },
                "legend": {
                    "title": "Home Range Percentiles",
                    "values": [
                        {
                            "label": "99th percentile",
                            "color": "#d2691e",
                        },
                    ],
                },
                "geodataframe": DependsOn("filter_percentile"),
            }
            | (params_dict.get("custom_home_range_layers") or {}),
            method="call",
        ),
        "combined_ldx_filtered_hr_layers": Node(
            async_task=combine_deckgl_map_layers.validate()
            .set_task_instance_id("combined_ldx_filtered_hr_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": [
                    DependsOn("create_ldx_styled_layers"),
                    DependsOn("create_ldx_text_layer"),
                ],
                "grouped_layers": DependsOn("custom_home_range_layers"),
            }
            | (params_dict.get("combined_ldx_filtered_hr_layers") or {}),
            method="call",
        ),
        "filtered_hr_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("filtered_hr_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("filter_percentile"),
                "pitch": 0,
                "bearing": 0,
            }
            | (params_dict.get("filtered_hr_view_state") or {}),
            method="call",
        ),
        "draw_filtered_hr_map": Node(
            async_task=draw_map.validate()
            .set_task_instance_id("draw_filtered_hr_map")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("configure_base_maps"),
                "static": False,
                "title": None,
                "max_zoom": 10,
                "legend_style": {
                    "placement": "bottom-right",
                },
                "geo_layers": DependsOn("combined_ldx_filtered_hr_layers"),
                "view_state": DependsOn("filtered_hr_view_state"),
            }
            | (params_dict.get("draw_filtered_hr_map") or {}),
            method="call",
        ),
        "persist_filtered_hr_html": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("persist_filtered_hr_html")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "filtered_homerange",
                "text": DependsOn("draw_filtered_hr_map"),
            }
            | (params_dict.get("persist_filtered_hr_html") or {}),
            method="call",
        ),
        "generate_recursion_raster": Node(
            async_task=generate_ecograph_raster.validate()
            .set_task_instance_id("generate_recursion_raster")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "step_length": 2000,
                "dist_col": "dist_meters",
                "interpolation": "mean",
                "movement_covariate": None,
                "radius": 2,
                "cutoff": None,
                "tortuosity_length": 3,
                "resolution": None,
                "network_metric": "weight",
                "output_dir": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "weighted_raster",
                "gdf": DependsOn("add_season_labels"),
            }
            | (params_dict.get("generate_recursion_raster") or {}),
            method="call",
        ),
        "extract_raster": Node(
            async_task=retrieve_feature_gdf.validate()
            .set_task_instance_id("extract_raster")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "file_path": DependsOn("generate_recursion_raster"),
            }
            | (params_dict.get("extract_raster") or {}),
            method="call",
        ),
        "sort_recursion_features": Node(
            async_task=sort_values.validate()
            .set_task_instance_id("sort_recursion_features")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "value",
                "na_position": "last",
                "ascending": True,
                "df": DependsOn("extract_raster"),
            }
            | (params_dict.get("sort_recursion_features") or {}),
            method="call",
        ),
        "classify_recursion_features": Node(
            async_task=apply_classification.validate()
            .set_task_instance_id("classify_recursion_features")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "input_column_name": "value",
                "output_column_name": "bins",
                "classification_options": {
                    "scheme": "natural_breaks",
                    "k": 6,
                },
                "label_options": {
                    "label_ranges": False,
                    "label_decimals": 1,
                },
                "df": DependsOn("sort_recursion_features"),
            }
            | (params_dict.get("classify_recursion_features") or {}),
            method="call",
        ),
        "apply_recursion_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("apply_recursion_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "input_column_name": "bins",
                "output_column_name": "recursion_bins_colors",
                "colormap": [
                    "#1a9850",
                    "#91cf60",
                    "#d9ef8b",
                    "#fee08b",
                    "#fc8d59",
                    "#d73027",
                ],
                "df": DependsOn("classify_recursion_features"),
            }
            | (params_dict.get("apply_recursion_colormap") or {}),
            method="call",
        ),
        "generate_recursion_layers": Node(
            async_task=create_geojson_layer.validate()
            .set_task_instance_id("generate_recursion_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "filled": True,
                    "stroked": True,
                    "extruded": False,
                    "wireframe": False,
                    "get_fill_color": "recursion_bins_colors",
                    "get_line_color": "recursion_bins_colors",
                    "opacity": 0.55,
                    "get_line_width": 1.55,
                    "get_elevation": 0,
                    "get_point_radius": 1,
                    "line_width_units": "pixels",
                    "line_width_scale": 1,
                    "line_width_min_pixels": 1,
                    "line_width_max_pixels": 5,
                },
                "legend": {
                    "title": "Recursion events",
                    "label_column": "bins",
                    "color_column": "recursion_bins_colors",
                    "sort": "ascending",
                    "label_suffix": None,
                },
                "geodataframe": DependsOn("apply_recursion_colormap"),
            }
            | (params_dict.get("generate_recursion_layers") or {}),
            method="call",
        ),
        "combined_ldx_recursion_layers": Node(
            async_task=combine_deckgl_map_layers.validate()
            .set_task_instance_id("combined_ldx_recursion_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": [
                    DependsOn("create_ldx_styled_layers"),
                    DependsOn("create_ldx_text_layer"),
                ],
                "grouped_layers": DependsOn("generate_recursion_layers"),
            }
            | (params_dict.get("combined_ldx_recursion_layers") or {}),
            method="call",
        ),
        "recursion_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("recursion_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("apply_recursion_colormap"),
                "pitch": 0,
                "bearing": 0,
            }
            | (params_dict.get("recursion_view_state") or {}),
            method="call",
        ),
        "draw_recursion_map": Node(
            async_task=draw_map.validate()
            .set_task_instance_id("draw_recursion_map")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("configure_base_maps"),
                "static": False,
                "title": None,
                "max_zoom": 10,
                "legend_style": {
                    "placement": "bottom-right",
                },
                "geo_layers": DependsOn("combined_ldx_recursion_layers"),
                "view_state": DependsOn("recursion_view_state"),
            }
            | (params_dict.get("draw_recursion_map") or {}),
            method="call",
        ),
        "persist_recursion_html": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("persist_recursion_html")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "recursion_events",
                "text": DependsOn("draw_recursion_map"),
            }
            | (params_dict.get("persist_recursion_html") or {}),
            method="call",
        ),
        "persist_strajs_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_strajs_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("add_season_labels"),
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "seasonal_trajectories",
            }
            | (params_dict.get("persist_strajs_geoparquet") or {}),
            method="call",
        ),
        "persist_strajs_csv": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_strajs_csv")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("add_season_labels"),
                "filetype": "csv",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "seasonal_trajectories",
            }
            | (params_dict.get("persist_strajs_csv") or {}),
            method="call",
        ),
        "mapbook_dashboard": Node(
            async_task=gather_dashboard.validate()
            .set_task_instance_id("mapbook_dashboard")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "details": DependsOn("workflow_details"),
                "time_range": DependsOn("time_range"),
                "groupers": DependsOn("groupers"),
            }
            | (params_dict.get("mapbook_dashboard") or {}),
            method="call",
        ),
    }
    graph = Graph(dependencies=dependencies, nodes=nodes)
    results = graph.execute()
    return results
